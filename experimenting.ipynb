{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/Swaroop/isro project/solar_flux_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['Date'].dt.year<1996]\n",
    "test_data = df[df['Date'].dt.year>=1996]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17853    75.000000\n",
       "17854    74.000000\n",
       "17855    80.000000\n",
       "17856    85.000000\n",
       "17857    84.000000\n",
       "           ...    \n",
       "26981    85.983333\n",
       "26982    84.433333\n",
       "26983    83.583333\n",
       "26984    82.733333\n",
       "26985    82.733333\n",
       "Name: sfu, Length: 9133, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sfu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequence = df['sfu']\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = df['sfu']\n",
    "# choose a number of time steps\n",
    "n_steps = 27\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# summarize the data\n",
    "# for i in range(len(X)):\n",
    "# \tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train_data['sfu'])\n",
    "test = np.array(test_data['sfu'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17853,), (9133,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17826, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[260.        ],\n",
       "        [244.5       ],\n",
       "        [229.        ],\n",
       "        ...,\n",
       "        [321.33333333],\n",
       "        [307.        ],\n",
       "        [286.        ]],\n",
       "\n",
       "       [[244.5       ],\n",
       "        [229.        ],\n",
       "        [213.5       ],\n",
       "        ...,\n",
       "        [307.        ],\n",
       "        [286.        ],\n",
       "        [265.        ]],\n",
       "\n",
       "       [[229.        ],\n",
       "        [213.5       ],\n",
       "        [198.        ],\n",
       "        ...,\n",
       "        [286.        ],\n",
       "        [265.        ],\n",
       "        [244.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 73.        ],\n",
       "        [ 73.        ],\n",
       "        [ 72.        ],\n",
       "        ...,\n",
       "        [ 74.        ],\n",
       "        [ 74.        ],\n",
       "        [ 76.        ]],\n",
       "\n",
       "       [[ 73.        ],\n",
       "        [ 72.        ],\n",
       "        [ 73.        ],\n",
       "        ...,\n",
       "        [ 74.        ],\n",
       "        [ 76.        ],\n",
       "        [ 76.        ]],\n",
       "\n",
       "       [[ 72.        ],\n",
       "        [ 73.        ],\n",
       "        [ 74.        ],\n",
       "        ...,\n",
       "        [ 76.        ],\n",
       "        [ 76.        ],\n",
       "        [ 75.        ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.reshape(train_X.shape[0], train_X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(np.array(train_data['sfu']), 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "# train_y, test_y = scaler.transform(train_y.reshape(-1, 1)), scaler.fit_transform(test_y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "557/557 [==============================] - 14s 22ms/step - loss: 16253.3154 - val_loss: 8041.3462\n",
      "Epoch 2/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 11579.0723 - val_loss: 5309.4609\n",
      "Epoch 3/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 8515.5439 - val_loss: 3567.5186\n",
      "Epoch 4/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 6389.9312 - val_loss: 2522.3845\n",
      "Epoch 5/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 4864.8794 - val_loss: 1745.8820\n",
      "Epoch 6/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 3644.0381 - val_loss: 1161.3800\n",
      "Epoch 7/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 2578.1575 - val_loss: 748.3306\n",
      "Epoch 8/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 1830.4130 - val_loss: 497.2511\n",
      "Epoch 9/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 1310.2946 - val_loss: 338.8114\n",
      "Epoch 10/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 936.0960 - val_loss: 237.3938\n",
      "Epoch 11/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 680.8915 - val_loss: 173.8650\n",
      "Epoch 12/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 530.2174 - val_loss: 134.9322\n",
      "Epoch 13/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 409.1035 - val_loss: 108.7379\n",
      "Epoch 14/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 325.7753 - val_loss: 90.2618\n",
      "Epoch 15/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 277.4540 - val_loss: 78.7881\n",
      "Epoch 16/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 245.4217 - val_loss: 70.4805\n",
      "Epoch 17/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 214.6332 - val_loss: 64.5285\n",
      "Epoch 18/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 193.7306 - val_loss: 64.5545\n",
      "Epoch 19/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 179.3167 - val_loss: 60.5262\n",
      "Epoch 20/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 175.0405 - val_loss: 59.9331\n",
      "Epoch 21/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 167.9296 - val_loss: 58.6456\n",
      "Epoch 22/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 157.9865 - val_loss: 59.0388\n",
      "Epoch 23/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 155.9271 - val_loss: 58.4011\n",
      "Epoch 24/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 150.6222 - val_loss: 68.2401\n",
      "Epoch 25/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 146.7389 - val_loss: 60.0157\n",
      "Epoch 26/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 144.4515 - val_loss: 60.1218\n",
      "Epoch 27/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 143.6715 - val_loss: 61.0722\n",
      "Epoch 28/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 146.5574 - val_loss: 58.3555\n",
      "Epoch 29/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 143.0239 - val_loss: 75.1595\n",
      "Epoch 30/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 138.4062 - val_loss: 57.6604\n",
      "Epoch 31/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 138.4447 - val_loss: 58.7741\n",
      "Epoch 32/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 141.3178 - val_loss: 60.3585\n",
      "Epoch 33/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 139.0681 - val_loss: 61.6206\n",
      "Epoch 34/100\n",
      "557/557 [==============================] - 11s 19ms/step - loss: 132.6455 - val_loss: 61.0742\n",
      "Epoch 35/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 132.6730 - val_loss: 61.8557\n",
      "Epoch 36/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 133.7431 - val_loss: 61.6265\n",
      "Epoch 37/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 137.2098 - val_loss: 64.2711\n",
      "Epoch 38/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 132.7809 - val_loss: 61.5931\n",
      "Epoch 39/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 130.1669 - val_loss: 60.3473\n",
      "Epoch 40/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 132.8261 - val_loss: 63.2965\n",
      "Epoch 41/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 130.6534 - val_loss: 61.9968\n",
      "Epoch 42/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 129.2069 - val_loss: 69.0504\n",
      "Epoch 43/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 132.3450 - val_loss: 63.4258\n",
      "Epoch 44/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 128.8685 - val_loss: 62.4664\n",
      "Epoch 45/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 126.7921 - val_loss: 64.8941\n",
      "Epoch 46/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 130.4714 - val_loss: 65.2672\n",
      "Epoch 47/100\n",
      "557/557 [==============================] - 12s 22ms/step - loss: 126.4336 - val_loss: 63.2510\n",
      "Epoch 48/100\n",
      "557/557 [==============================] - 11s 21ms/step - loss: 125.4771 - val_loss: 61.2647\n",
      "Epoch 49/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 129.8597 - val_loss: 63.1821\n",
      "Epoch 50/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 126.9466 - val_loss: 62.0158\n",
      "Epoch 51/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 127.2790 - val_loss: 61.1604\n",
      "Epoch 52/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 124.8008 - val_loss: 64.5911\n",
      "Epoch 53/100\n",
      "557/557 [==============================] - 11s 21ms/step - loss: 123.6750 - val_loss: 60.8229\n",
      "Epoch 54/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 124.1609 - val_loss: 61.1244\n",
      "Epoch 55/100\n",
      "557/557 [==============================] - 11s 19ms/step - loss: 125.2285 - val_loss: 61.9113\n",
      "Epoch 56/100\n",
      "557/557 [==============================] - 11s 19ms/step - loss: 124.5006 - val_loss: 64.3667\n",
      "Epoch 57/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 123.7989 - val_loss: 61.0192\n",
      "Epoch 58/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 125.2856 - val_loss: 62.6433\n",
      "Epoch 59/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 123.1336 - val_loss: 65.1076\n",
      "Epoch 60/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 119.3960 - val_loss: 62.9548\n",
      "Epoch 61/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 121.2793 - val_loss: 69.0403\n",
      "Epoch 62/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 123.4584 - val_loss: 63.0438\n",
      "Epoch 63/100\n",
      "557/557 [==============================] - 11s 19ms/step - loss: 123.4329 - val_loss: 64.5499\n",
      "Epoch 64/100\n",
      "557/557 [==============================] - 11s 21ms/step - loss: 123.5662 - val_loss: 62.5013\n",
      "Epoch 65/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 122.5372 - val_loss: 65.7558\n",
      "Epoch 66/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 120.0061 - val_loss: 61.7248\n",
      "Epoch 67/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 121.6646 - val_loss: 62.0589\n",
      "Epoch 68/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 119.1807 - val_loss: 63.6899\n",
      "Epoch 69/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 119.8779 - val_loss: 63.8176\n",
      "Epoch 70/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 117.9455 - val_loss: 62.9974\n",
      "Epoch 71/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 119.0407 - val_loss: 64.2737\n",
      "Epoch 72/100\n",
      "557/557 [==============================] - 13s 23ms/step - loss: 119.3773 - val_loss: 60.7190\n",
      "Epoch 73/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 121.7910 - val_loss: 62.9171\n",
      "Epoch 74/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 122.0266 - val_loss: 64.6560\n",
      "Epoch 75/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 118.5535 - val_loss: 63.0544\n",
      "Epoch 76/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 120.4417 - val_loss: 66.0661\n",
      "Epoch 77/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 116.8874 - val_loss: 62.5699\n",
      "Epoch 78/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 118.5596 - val_loss: 64.7252\n",
      "Epoch 79/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 119.1473 - val_loss: 66.5052\n",
      "Epoch 80/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 118.2000 - val_loss: 63.7352\n",
      "Epoch 81/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 121.0844 - val_loss: 67.6574\n",
      "Epoch 82/100\n",
      "557/557 [==============================] - 12s 22ms/step - loss: 117.9448 - val_loss: 66.8547\n",
      "Epoch 83/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 118.6326 - val_loss: 63.0636\n",
      "Epoch 84/100\n",
      "557/557 [==============================] - 11s 21ms/step - loss: 116.7132 - val_loss: 64.1996\n",
      "Epoch 85/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 117.4009 - val_loss: 63.1068\n",
      "Epoch 86/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 119.5867 - val_loss: 64.4619\n",
      "Epoch 87/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 117.2417 - val_loss: 64.7141\n",
      "Epoch 88/100\n",
      "557/557 [==============================] - 13s 23ms/step - loss: 114.7531 - val_loss: 62.6657\n",
      "Epoch 89/100\n",
      "557/557 [==============================] - 12s 22ms/step - loss: 114.9799 - val_loss: 69.2864\n",
      "Epoch 90/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 115.8050 - val_loss: 66.0218\n",
      "Epoch 91/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 116.2185 - val_loss: 64.5781\n",
      "Epoch 92/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 116.7144 - val_loss: 63.4965\n",
      "Epoch 93/100\n",
      "557/557 [==============================] - 12s 22ms/step - loss: 115.5072 - val_loss: 64.9526\n",
      "Epoch 94/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 114.2778 - val_loss: 66.8006\n",
      "Epoch 95/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 118.8238 - val_loss: 63.6914\n",
      "Epoch 96/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 116.5279 - val_loss: 64.0806\n",
      "Epoch 97/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 115.6377 - val_loss: 71.3992\n",
      "Epoch 98/100\n",
      "557/557 [==============================] - 13s 23ms/step - loss: 113.0110 - val_loss: 61.7021\n",
      "Epoch 99/100\n",
      "557/557 [==============================] - 11s 20ms/step - loss: 115.3988 - val_loss: 63.7593\n",
      "Epoch 100/100\n",
      "557/557 [==============================] - 12s 21ms/step - loss: 115.8336 - val_loss: 64.7553\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "n_steps = 54\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='tanh', input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "# optimizer = SGD(lr = 0.001)\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('model_weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=100, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 3s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9655827532666791\n",
      "RMSE:  8.047067086158675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('singlelayerLSTM.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with 64 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 8s 12ms/step - loss: 4503.5581 - val_loss: 425.3190\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 435.6338 - val_loss: 252.2152\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 295.8269 - val_loss: 208.0896\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 258.1609 - val_loss: 192.5838\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 7s 12ms/step - loss: 227.2689 - val_loss: 176.0780\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 182.7075 - val_loss: 132.9037\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 442.1055 - val_loss: 233.8338\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 7s 12ms/step - loss: 258.0867 - val_loss: 215.4211\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 243.1081 - val_loss: 210.2695\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 236.6810 - val_loss: 226.9820\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 1673680.1250 - val_loss: 276.3605\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 358.4421 - val_loss: 276.4321\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 357.5655 - val_loss: 275.9527\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 356.9322 - val_loss: 275.6900\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 358.4970 - val_loss: 275.3464\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 357.8492 - val_loss: 274.9400\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 359.0447 - val_loss: 274.5869\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 360.0374 - val_loss: 275.4337\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 361.7190 - val_loss: 272.7199\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 360.9567 - val_loss: 273.6111\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 361.3717 - val_loss: 273.7612\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 6s 10ms/step - loss: 363.9942 - val_loss: 289.9722\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 362.5893 - val_loss: 274.0020\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 369.0085 - val_loss: 333.1659\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 370.6401 - val_loss: 382.9850\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 380.8210 - val_loss: 259.5398\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 396.8937 - val_loss: 269.1115\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 389.7912 - val_loss: 351.2415\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 398.2259 - val_loss: 291.1843\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 368.9592 - val_loss: 246.9890\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 401.6204 - val_loss: 254.9227\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 345.0087 - val_loss: 249.4946\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 384.1435 - val_loss: 237.7952\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 389.2932 - val_loss: 235.8593\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 369.3489 - val_loss: 367.2217\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 383.5873 - val_loss: 282.6886\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 322.7992 - val_loss: 490.8633\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 307.5106 - val_loss: 284.4029\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 324.0529 - val_loss: 194.1569\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 290.6884 - val_loss: 183.7197\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 605.9431 - val_loss: 225.9863\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 283.3184 - val_loss: 234.2944\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 260.1814 - val_loss: 178.7584\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 7s 13ms/step - loss: 219.5814 - val_loss: 188.6532\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 187.6918 - val_loss: 128.7830\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 151.0239 - val_loss: 143.1964\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 128.9653 - val_loss: 111.6333\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 106.2954 - val_loss: 96.1018\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 98.6741 - val_loss: 89.2796\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 6s 11ms/step - loss: 79.5969 - val_loss: 94.3448\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('singleLSTM64.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9498129583135507\n",
      "RMSE:  9.713121414944831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layer LSTM with 64 32 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 14s 21ms/step - loss: 15805.8418 - val_loss: 450.5784\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 12s 21ms/step - loss: 319.1072 - val_loss: 255.3444\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 12s 22ms/step - loss: 196.1938 - val_loss: 262.3435\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 408.4316 - val_loss: 379.1798\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 434.1399 - val_loss: 351.2359\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 337.5121 - val_loss: 262.4095\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 714.4034 - val_loss: 402.0923\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 12s 21ms/step - loss: 599.0800 - val_loss: 468.7356\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 586.9237 - val_loss: 396.5370\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 531.5410 - val_loss: 362.4037\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 481.7991 - val_loss: 335.3112\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 461.1942 - val_loss: 316.4439\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 398.8496 - val_loss: 302.0464\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 369.1407 - val_loss: 280.0127\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 347.2525 - val_loss: 270.6182\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 328.3892 - val_loss: 259.3163\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 12s 21ms/step - loss: 309.8723 - val_loss: 241.8510\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 291.5658 - val_loss: 251.7606\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 228.0810 - val_loss: 298.3357\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 4198.8677 - val_loss: 445.6480\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 643.8745 - val_loss: 424.2426\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 590.5996 - val_loss: 423.5844\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 578.5328 - val_loss: 418.2102\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 575.4553 - val_loss: 407.7183\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 563.7545 - val_loss: 358.2567\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 385.2749 - val_loss: 194.2414\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 423.0161 - val_loss: 256.3700\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 347.0204 - val_loss: 215.2799\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 318.0278 - val_loss: 241.9208\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 258.9792 - val_loss: 204.4551\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 249.9405 - val_loss: 265.5833\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 245.8081 - val_loss: 177.7449\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 202.2962 - val_loss: 167.2375\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 171.2252 - val_loss: 140.8076\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 158.8999 - val_loss: 133.1000\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 143.7871 - val_loss: 223.0157\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 128.0381 - val_loss: 116.0434\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 142.2102 - val_loss: 130.8047\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 116.7431 - val_loss: 107.2717\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 98.6610 - val_loss: 104.5254\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 87.3577 - val_loss: 157.6953\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 75.3224 - val_loss: 85.0551\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 63.2887 - val_loss: 92.0179\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 58.0528 - val_loss: 92.0586\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 45.8617 - val_loss: 71.9153\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 11s 20ms/step - loss: 39.8958 - val_loss: 83.2852\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 10s 19ms/step - loss: 38.0812 - val_loss: 68.3494\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 34.1149 - val_loss: 71.3868\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 32.0667 - val_loss: 73.5370\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 11s 19ms/step - loss: 30.5855 - val_loss: 64.6051\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu',return_sequences= True,  input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('2LayerLSTM6432.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAGsCAYAAADDkV+PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbKklEQVR4nO3de3wU9b3/8dfeN/dAkIRIgLTKTRERFKOWeskhIlJR2uOFKq2op22wIvXGr5Xa2pYW610qtT0VewreegpHQdEUFFqJiNEoIkTUSFBIokCyJCR7nd8fm51kJQhJNtlNeD8fj3nszsx3Z7+bSeCdT77zHYthGAYiIiIiIr2YNd4dEBERERHpKoVaEREREen1FGpFREREpNdTqBURERGRXk+hVkRERER6PYVaEREREen1FGpFREREpNezx7sD8RQKhdi9ezdpaWlYLJZ4d0dEREREvsQwDA4cOEBubi5W6+Hrscd0qN29ezd5eXnx7oaIiIiIHMGuXbsYPHjwYfcf06E2LS0NCH+R0tPT49wbEREREfkyj8dDXl6emdsO55gOtZEhB+np6Qq1IiIiIgnsSENFdaGYiIiIiPR6CrUiIiIi0usp1IqIiIhIr3dMj6kVERGRY0swGMTv98e7G9KGw+HAZrN1+TgKtSIiItLnGYZBdXU1dXV18e6KtCMzM5OcnJwu3TdAoVZERET6vEigHThwIMnJybrpUoIwDIODBw9SW1sLwKBBgzp9LIVaERER6dOCwaAZaLOysuLdHfmSpKQkAGpraxk4cGCnhyJ0+EKxDRs2MG3aNHJzc7FYLKxcufKQNtu2beNb3/oWGRkZpKSkcPrpp1NVVWXub25upri4mKysLFJTU5kxYwY1NTVRx6iqqmLq1KkkJyczcOBAbr31VgKBQFSbV199ldNOOw2Xy8UJJ5zA0qVLO/pxREREpI+LjKFNTk6Oc0/kcCLnpivjnTscahsbGxk7diyLFy9ud/9HH33EOeecw8iRI3n11Vd59913ufPOO3G73Wabm2++meeff55nn32W9evXs3v3bi677DJzfzAYZOrUqfh8PjZu3MgTTzzB0qVLWbBggdmmsrKSqVOnct5551FeXs7cuXO57rrreOmllzr6kUREROQYoCEHiSsW58ZiGIbRlQ6sWLGC6dOnm9uuuOIKHA4H//M//9Pua+rr6znuuONYvnw53/72twHYvn07o0aNorS0lDPPPJMXX3yRiy++mN27d5OdnQ3AkiVLuP322/n8889xOp3cfvvtrF69mvfeey/qvevq6lizZk277+31evF6veZ65LZr9fX1uqOYiIhIH9Xc3ExlZSX5+flRRTZJHF91jjweDxkZGUfMazGdpzYUCrF69WqGDx9OUVERAwcOZOLEiVFDFMrKyvD7/RQWFprbRo4cyZAhQygtLQWgtLSUMWPGmIEWoKioCI/Hw9atW802bY8RaRM5RnsWLlxIRkaGueTl5cXiY4uIiIhInMU01NbW1tLQ0MBvf/tbLrzwQl5++WUuvfRSLrvsMtavXw+Erz50Op1kZmZGvTY7O5vq6mqzTdtAG9kf2fdVbTweD01NTe32b/78+dTX15vLrl27uvyZRURERLrLueeey9y5c+PdjV4hprMfhEIhAC655BJuvvlmAE499VQ2btzIkiVL+OY3vxnLt+swl8uFy+WKax9EREREJPZiWqkdMGAAdrud0aNHR20fNWqUOftBTk4OPp/vkMmPa2pqyMnJMdt8eTaEyPqR2qSnp5tTQySSg74AGz/6gtc+/CLeXRERERHpc2Iaap1OJ6effjoVFRVR2z/44AOGDh0KwPjx43E4HKxdu9bcX1FRQVVVFQUFBQAUFBSwZcsWcyJegJKSEtLT083AXFBQEHWMSJvIMRLNnvpmrvrTJn7wt7J4d0VEROSYZxgGB32BuCydvUZ///79XHPNNfTr14/k5GSmTJnCjh07zP07d+5k2rRp9OvXj5SUFE466SReeOEF87UzZ87kuOOOIykpiRNPPJHHH388Jl/LRNHh4QcNDQ18+OGH5nplZSXl5eX079+fIUOGcOutt3L55ZczadIkzjvvPNasWcPzzz/Pq6++CkBGRgazZ89m3rx59O/fn/T0dG688UYKCgo488wzAZg8eTKjR4/m6quvZtGiRVRXV/Ozn/2M4uJic/jAD37wAx555BFuu+02rr32WtatW8czzzzD6tWrY/BliT23IzyRsDcQinNPREREpMkfZPSC+EwD+v4vi0h2dnwE6Pe+9z127NjBc889R3p6OrfffjsXXXQR77//Pg6Hg+LiYnw+Hxs2bCAlJYX333+f1NRUAO68807ef/99XnzxRQYMGMCHH3542GuQeqsOf0XffPNNzjvvPHN93rx5AMyaNYulS5dy6aWXsmTJEhYuXMiPf/xjRowYwf/+7/9yzjnnmK+5//77sVqtzJgxA6/XS1FREX/4wx/M/TabjVWrVvHDH/6QgoICUlJSmDVrFr/85S/NNvn5+axevZqbb76ZBx98kMGDB/PnP/+ZoqKiTn0hupvbHi6K+wIhQiEDq1Vz5YmIiMjRiYTZ1157jbPOOguAZcuWkZeXx8qVK/nOd75DVVUVM2bMYMyYMQB87WtfM19fVVXFuHHjmDBhAgDDhg3r8c/Q3bo0T21vd7TznsVCgzfAyT8P/0a4/e4LzcqtiIiIdK/25kA1DIMmfzAu/Uly2I76ZgPnnnsup556Kueffz4zZsygubk56jay48aN49JLL2XBggX8+c9/5oc//CFnnHEGhYWFzJgxg1NOOQWAF198kRkzZjB8+HAmT57M9OnTzXCcCBJunlo5vEilFqA5Tj9EIiIiEmaxWEh22uOydNedza677jo+/vhjrr76arZs2cKECRN4+OGHAZgyZQo7d+7k5ptvZvfu3VxwwQXccsst3dKPeFGo7SF2mxVby5ADjasVERGRjhg1ahSBQIBNmzaZ2/bu3UtFRUXUrFN5eXn84Ac/4B//+Ac/+clP+NOf/mTuO+6445g1axZ/+9vfeOCBB3jsscd69DN0t5jOUytfzW230ugLqlIrIiIiHXLiiSdyySWXcP311/PHP/6RtLQ07rjjDo4//nguueQSAObOncuUKVMYPnw4+/fv55VXXmHUqFEALFiwgPHjx3PSSSfh9XpZtWqVua+vUKW2B7laxtE2+1WpFRERkY55/PHHGT9+PBdffDEFBQUYhsELL7yAw+EAIBgMUlxczKhRo7jwwgsZPny4eSG+0+lk/vz5nHLKKUyaNAmbzcZTTz0Vz48Tc7pQrIcuFAM4a+Fadtc389ycszllcGa3v5+IiIh89UVIkhh0oVgv41alVkRERKRbKNT2IGfLDAjegMbUioiIiMSSQm0PUqVWREREpHso1PYglyq1IiIiIt1CobYHqVIrIiIi0j0UantQpFKreWpFREREYkuhtgdFKrW6o5iIiIhIbCnU9iC3Q5VaERERke6gUNuDXHZVakVERES6g0JtD4pUar2q1IqIiEgPGDZsGA888MBRtbVYLKxcubJb+9OdFGp7kCq1IiIiIt1DobYHaUytiIiISPdQqO1BkUqtQq2IiEicGQb4GuOzGMZRdfGxxx4jNzeXUCj6L7yXXHIJ1157LR999BGXXHIJ2dnZpKamcvrpp/PPf/4zZl+iLVu2cP7555OUlERWVhY33HADDQ0N5v5XX32VM844g5SUFDIzMzn77LPZuXMnAO+88w7nnXceaWlppKenM378eN58882Y9a099m49ukQxx9Rq+IGIiEh8+Q/Cb3Lj897/bzc4U47Y7Dvf+Q433ngjr7zyChdccAEA+/btY82aNbzwwgs0NDRw0UUX8etf/xqXy8Vf//pXpk2bRkVFBUOGDOlSFxsbGykqKqKgoIDNmzdTW1vLddddx5w5c1i6dCmBQIDp06dz/fXX8+STT+Lz+XjjjTewWCwAzJw5k3HjxvHoo49is9koLy/H4XB0qU9HolDbg1wOVWpFRETk6PTr148pU6awfPlyM9T+/e9/Z8CAAZx33nlYrVbGjh1rtr/77rtZsWIFzz33HHPmzOnSey9fvpzm5mb++te/kpISDuCPPPII06ZN43e/+x0Oh4P6+nouvvhivv71rwMwatQo8/VVVVXceuutjBw5EoATTzyxS/05Ggq1PShyRzFVakVEROLMkRyumMbrvY/SzJkzuf766/nDH/6Ay+Vi2bJlXHHFFVitVhoaGrjrrrtYvXo1e/bsIRAI0NTURFVVVZe7uG3bNsaOHWsGWoCzzz6bUChERUUFkyZN4nvf+x5FRUX8x3/8B4WFhfznf/4ngwYNAmDevHlcd911/M///A+FhYV85zvfMcNvd9GY2h7kVqVWREQkMVgs4SEA8Vha/kR/NKZNm4ZhGKxevZpdu3bxr3/9i5kzZwJwyy23sGLFCn7zm9/wr3/9i/LycsaMGYPP5+uur1qUxx9/nNLSUs466yyefvpphg8fzuuvvw7AXXfdxdatW5k6dSrr1q1j9OjRrFixolv7o1Dbg1SpFRERkY5wu91cdtllLFu2jCeffJIRI0Zw2mmnAfDaa6/xve99j0svvZQxY8aQk5PDJ598EpP3HTVqFO+88w6NjY3mttdeew2r1cqIESPMbePGjWP+/Pls3LiRk08+meXLl5v7hg8fzs0338zLL7/MZZddxuOPPx6Tvh2OQm0PUqVWREREOmrmzJmsXr2av/zlL2aVFsLjVP/xj39QXl7OO++8w1VXXXXITAldeU+3282sWbN47733eOWVV7jxxhu5+uqryc7OprKykvnz51NaWsrOnTt5+eWX2bFjB6NGjaKpqYk5c+bw6quvsnPnTl577TU2b94cNea2O2hMbQ+KVGqb/arUioiIyNE5//zz6d+/PxUVFVx11VXm9vvuu49rr72Ws846iwEDBnD77bfj8Xhi8p7Jycm89NJL3HTTTZx++ukkJyczY8YM7rvvPnP/9u3beeKJJ9i7dy+DBg2iuLiY//qv/yIQCLB3716uueYaampqGDBgAJdddhm/+MUvYtK3w7EYxlFOltYHeTweMjIyqK+vJz09vdvfb9seD1Me/BcDUl28+bPCbn8/ERERgebmZiorK8nPz8ftdse7O9KOrzpHR5vXNPygB0WGH3g1/EBEREQkphRqe5AuFBMREZF4WLZsGampqe0uJ510Ury7FxMaU9uDIpVaXzBEMGRgsx79lB4iIiIinfWtb32LiRMntruvu+/01VMUantQpFIL4AuESHLa4tgbEREROVakpaWRlpYW7250Kw0/6EFtQ62m9RIREelZsZruSmIvFudGldoeZLdZsVstBEIGzQGFWhERkZ7gdDqxWq3s3r2b4447DqfTiaUDd/WS7mMYBj6fj88//xyr1YrT6ez0sRRqe5jbYaPBG8CruWpFRER6hNVqJT8/nz179rB79+54d0fakZyczJAhQ7BaOz+IoMOhdsOGDdxzzz2UlZWxZ88eVqxYwfTp09tt+4Mf/IA//vGP3H///cydO9fcvm/fPm688Uaef/55rFYrM2bM4MEHHyQ1NdVs8+6771JcXMzmzZs57rjjuPHGG7ntttuijv/ss89y55138sknn3DiiSfyu9/9josuuqijH6lHuR1WGryoUisiItKDnE4nQ4YMIRAIEAzq/+BEYrPZsNvtXa6edzjUNjY2MnbsWK699louu+yyw7ZbsWIFr7/+Orm5uYfsmzlzJnv27KGkpAS/38/3v/99brjhBvN+wR6Ph8mTJ1NYWMiSJUvYsmUL1157LZmZmdxwww0AbNy4kSuvvJKFCxdy8cUXs3z5cqZPn85bb73FySef3NGP1WNc9shctarUioiI9CSLxYLD4egzV/tLtA6H2ilTpjBlypSvbPPZZ59x44038tJLLzF16tSofdu2bWPNmjVs3ryZCRMmAPDwww9z0UUX8fvf/57c3FyWLVuGz+fjL3/5C06nk5NOOony8nLuu+8+M9Q++OCDXHjhhdx6660A3H333ZSUlPDII4+wZMmSjn6sHuNyRG6Vq98SRURERGIl5rMfhEIhrr76am699dZ2J/MtLS0lMzPTDLQAhYWFWK1WNm3aZLaZNGlS1GDhoqIiKioq2L9/v9mmsDD6VrNFRUWUlpYetm9erxePxxO19DSzUqsbMIiIiIjETMxD7e9+9zvsdjs//vGP291fXV3NwIEDo7bZ7Xb69+9PdXW12SY7OzuqTWT9SG0i+9uzcOFCMjIyzCUvL69jHy4G3KrUioiIiMRcTENtWVkZDz74IEuXLk3IqTLmz59PfX29uezatavH+xCZq7ZZlVoRERGRmIlpqP3Xv/5FbW0tQ4YMwW63Y7fb2blzJz/5yU8YNmwYADk5OdTW1ka9LhAIsG/fPnJycsw2NTU1UW0i60dqE9nfHpfLRXp6etTS0yK3yvWqUisiIiISMzENtVdffTXvvvsu5eXl5pKbm8utt97KSy+9BEBBQQF1dXWUlZWZr1u3bh2hUMi8J3FBQQEbNmzA7/ebbUpKShgxYgT9+vUz26xduzbq/UtKSigoKIjlR4o5d8uYWlVqRURERGKnw7MfNDQ08OGHH5rrlZWVlJeX079/f4YMGUJWVlZUe4fDQU5ODiNGjABg1KhRXHjhhVx//fUsWbIEv9/PnDlzuOKKK8zpv6666ip+8YtfMHv2bG6//Xbee+89HnzwQe6//37zuDfddBPf/OY3uffee5k6dSpPPfUUb775Jo899linvhA9JTL7gSq1IiIiIrHT4Urtm2++ybhx4xg3bhwA8+bNY9y4cSxYsOCoj7Fs2TJGjhzJBRdcwEUXXcQ555wTFUYzMjJ4+eWXqaysZPz48fzkJz9hwYIF5nReAGeddRbLly/nscceY+zYsfz9739n5cqVCT1HLbRWajX7gYiIiEjsWAzDMOLdiXjxeDxkZGRQX1/fY+NrF/zfe/y1dCc/Pv8E5k0e0SPvKSIiItJbHW1ei/mUXvLVIheKaUytiIiISOwo1PYwc0ovjakVERERiRmF2h7WOqWXKrUiIiIisaJQ28Nab76gSq2IiIhIrCjU9jCXKrUiIiIiMadQ28PcqtSKiIiIxJxCbQ9TpVZEREQk9hRqe5gqtSIiIiKxp1DbwyKV2mZVakVERERiRqG2h0UqtV5VakVERERiRqG2h2meWhEREZHYU6jtYS6HKrUiIiIisaZQ28Pcdo2pFREREYk1hdoepkqtiIiISOwp1PawSKXWHzQIhow490ZERESkb1Co7WGRSi1As1/VWhEREZFYUKjtYZFKLYA3oHG1IiIiIrGgUNvDrFYLTlvLXcVUqRURERGJCYXaOHCZN2BQpVZEREQkFhRq46D1Vrmq1IqIiIjEgkJtHKhSKyIiIhJbCrVx4HZoTK2IiIhILCnUxoHLruEHIiIiIrGkUBsHboeGH4iIiIjEkkJtHLh1oZiIiIhITCnUxoEuFBMRERGJLYXaOIhUar2q1IqIiIjEhEJtHKhSKyIiIhJbCrVxoDG1IiIiIrGlUBsHkUpts1+VWhEREZFYUKiNA3NMbUCVWhEREZFYUKiNA5c5/ECVWhEREZFYUKiNg9YLxVSpFREREYmFDofaDRs2MG3aNHJzc7FYLKxcudLc5/f7uf322xkzZgwpKSnk5uZyzTXXsHv37qhj7Nu3j5kzZ5Kenk5mZiazZ8+moaEhqs27777LN77xDdxuN3l5eSxatOiQvjz77LOMHDkSt9vNmDFjeOGFFzr6ceLCrUqtiIiISEx1ONQ2NjYyduxYFi9efMi+gwcP8tZbb3HnnXfy1ltv8Y9//IOKigq+9a1vRbWbOXMmW7dupaSkhFWrVrFhwwZuuOEGc7/H42Hy5MkMHTqUsrIy7rnnHu666y4ee+wxs83GjRu58sormT17Nm+//TbTp09n+vTpvPfeex39SD1OlVoRERGR2LIYhmF0+sUWCytWrGD69OmHbbN582bOOOMMdu7cyZAhQ9i2bRujR49m8+bNTJgwAYA1a9Zw0UUX8emnn5Kbm8ujjz7KT3/6U6qrq3E6nQDccccdrFy5ku3btwNw+eWX09jYyKpVq8z3OvPMMzn11FNZsmTJUfXf4/GQkZFBfX096enpnfwqdNzfyz7llmff4ZvDj+OJa8/osfcVERER6W2ONq91+5ja+vp6LBYLmZmZAJSWlpKZmWkGWoDCwkKsViubNm0y20yaNMkMtABFRUVUVFSwf/9+s01hYWHUexUVFVFaWnrYvni9XjweT9QSD61TeqlSKyIiIhIL3Rpqm5ubuf3227nyyivNZF1dXc3AgQOj2tntdvr37091dbXZJjs7O6pNZP1IbSL727Nw4UIyMjLMJS8vr2sfsJNap/TSmFoRERGRWOi2UOv3+/nP//xPDMPg0Ucf7a636ZD58+dTX19vLrt27YpLP9wOVWpFREREYsneHQeNBNqdO3eybt26qPEPOTk51NbWRrUPBALs27ePnJwcs01NTU1Um8j6kdpE9rfH5XLhcrk6/8FixGUPV2p9qtSKiIiIxETMK7WRQLtjxw7++c9/kpWVFbW/oKCAuro6ysrKzG3r1q0jFAoxceJEs82GDRvw+/1mm5KSEkaMGEG/fv3MNmvXro06dklJCQUFBbH+SDGnSq2IiIhIbHU41DY0NFBeXk55eTkAlZWVlJeXU1VVhd/v59vf/jZvvvkmy5YtIxgMUl1dTXV1NT6fD4BRo0Zx4YUXcv311/PGG2/w2muvMWfOHK644gpyc3MBuOqqq3A6ncyePZutW7fy9NNP8+CDDzJv3jyzHzfddBNr1qzh3nvvZfv27dx11128+eabzJkzJwZflu4VqdRqTK2IiIhIjBgd9MorrxjAIcusWbOMysrKdvcBxiuvvGIeY+/evcaVV15ppKamGunp6cb3v/9948CBA1Hv88477xjnnHOO4XK5jOOPP9747W9/e0hfnnnmGWP48OGG0+k0TjrpJGP16tUd+iz19fUGYNTX13f0y9Aln3zRYAy9fZUx+s4Xe/R9RURERHqbo81rXZqntreL1zy11fXNnLlwLTarhY9+c1GPva+IiIhIb5Mw89TKoSJjaoMhg0BQQxBEREREukqhNg4i89QCNGtcrYiIiEiXKdTGgdPW+mX3agYEERERkS5TqI0Dq9WCM3KrXFVqRURERLpMoTZOXC2hVpVaERERka5TqI2TyLjaZr8qtSIiIiJdpVAbJy5z+IEqtSIiIiJdpVAbJ5FKrVeVWhEREZEuU6iNk8hctarUioiIiHSdQm2cuOyq1IqIiIjEikJtnEQqtV5VakVERES6TKE2TlSpFREREYkdhdo40ZhaERERkdhRqI2TSKW2WTdfEBEREekyhdo4McfUaviBiIiISJcp1MaJWanV8AMRERGRLlOojROXKrUiIiIiMaNQGyduVWpFREREYkahNk5UqRURERGJHYXaOGmt1CrUioiIiHSVQm2cRCq1mtJLREREpOsUauMkUqn1qlIrIiIi0mUKtXHidujmCyIiIiKxolAbJy57y4ViqtSKiIiIdJlCbZxEKrVeVWpFREREukyhNk7MKb1UqRURERHpMoXaODGn9FKlVkRERKTLFGrjRFN6iYiIiMSOQm2caEovERERkdhRqI0Td5tKrWEYce6NiIiISO+mUBsnrpZKbciAQEihVkRERKQrFGrjJDKmFjSuVkRERKSrFGrjJHLzBdC4WhEREZGuUqiNE4vFYgZbVWpFREREuqbDoXbDhg1MmzaN3NxcLBYLK1eujNpvGAYLFixg0KBBJCUlUVhYyI4dO6La7Nu3j5kzZ5Kenk5mZiazZ8+moaEhqs27777LN77xDdxuN3l5eSxatOiQvjz77LOMHDkSt9vNmDFjeOGFFzr6ceKqNdSqUisiIiLSFR0OtY2NjYwdO5bFixe3u3/RokU89NBDLFmyhE2bNpGSkkJRURHNzc1mm5kzZ7J161ZKSkpYtWoVGzZs4IYbbjD3ezweJk+ezNChQykrK+Oee+7hrrvu4rHHHjPbbNy4kSuvvJLZs2fz9ttvM336dKZPn857773X0Y8UN+atcgOq1IqIiIh0hcXownxSFouFFStWMH36dCBcpc3NzeUnP/kJt9xyCwD19fVkZ2ezdOlSrrjiCrZt28bo0aPZvHkzEyZMAGDNmjVcdNFFfPrpp+Tm5vLoo4/y05/+lOrqapxOJwB33HEHK1euZPv27QBcfvnlNDY2smrVKrM/Z555JqeeeipLliw5qv57PB4yMjKor68nPT29s1+GTpu06BWq9h3kf394FuOH9uvx9xcRERFJdEeb12I6prayspLq6moKCwvNbRkZGUycOJHS0lIASktLyczMNAMtQGFhIVarlU2bNpltJk2aZAZagKKiIioqKti/f7/Zpu37RNpE3qc9Xq8Xj8cTtcRTZPiBKrUiIiIiXRPTUFtdXQ1AdnZ21Pbs7GxzX3V1NQMHDozab7fb6d+/f1Sb9o7R9j0O1yayvz0LFy4kIyPDXPLy8jr6EWPKHH6gMbUiIiIiXXJMzX4wf/586uvrzWXXrl1x7Y8qtSIiIiKxEdNQm5OTA0BNTU3U9pqaGnNfTk4OtbW1UfsDgQD79u2LatPeMdq+x+HaRPa3x+VykZ6eHrXEU6RSq9kPRERERLompqE2Pz+fnJwc1q5da27zeDxs2rSJgoICAAoKCqirq6OsrMxss27dOkKhEBMnTjTbbNiwAb/fb7YpKSlhxIgR9OvXz2zT9n0ibSLv0xtonloRERGR2OhwqG1oaKC8vJzy8nIgfHFYeXk5VVVVWCwW5s6dy69+9Suee+45tmzZwjXXXENubq45Q8KoUaO48MILuf7663njjTd47bXXmDNnDldccQW5ubkAXHXVVTidTmbPns3WrVt5+umnefDBB5k3b57Zj5tuuok1a9Zw7733sn37du666y7efPNN5syZ0/WvSg9pndJLlVoRERGRrrB39AVvvvkm5513nrkeCZqzZs1i6dKl3HbbbTQ2NnLDDTdQV1fHOeecw5o1a3C73eZrli1bxpw5c7jggguwWq3MmDGDhx56yNyfkZHByy+/THFxMePHj2fAgAEsWLAgai7bs846i+XLl/Ozn/2M//f//h8nnngiK1eu5OSTT+7UFyIeXA5VakVERERioUvz1PZ28Z6ndv4/tvDkG1XM+4/h/PiCE3v8/UVEREQSXVzmqZWOcatSKyIiIhITCrVx5LJrTK2IiIhILCjUxpEqtSIiIiKxoVAbR5FKreapFREREekahdo4ilRqdUcxERERka5RqI0j3VFMREREJDYUauMockcxVWpFREREukahNo7MO4qpUisiIiLSJQq1caRKrYiIiEhsKNTGkcbUioiIiMSGQm0cRSq1zarUioiIiHSJQm0caUytiIiISGwo1MaReUcxVWpFREREukShNo4idxRTpVZERESkaxRq48jVplJrGEaceyMiIiLSeynUxlGkUmsY4A8q1IqIiIh0lkJtHEXG1ILG1YqIiIh0hUJtHDltViyW8PNmv0KtiIiISGcp1MaRxWJpvauYLhYTERER6TSF2jgz56rV8AMRERGRTlOojTPzrmKq1IqIiIh0mkJtnKlSKyIiItJ1CrVxpjG1IiIiIl2nUBtnkUqtpvQSERER6TyF2jjTmFoRERGRrlOojTONqRURERHpOoXaOIvcKleVWhEREZHOU6iNM5cjcqGYKrUiIiIinaVQG2fuSKU2oEqtiIiISGcp1MZZa6VWoVZERESksxRq46y1UqvhByIiIiKdpVAbZ5FKbbPG1IqIiIh0mkJtnEUqtV6NqRURERHptJiH2mAwyJ133kl+fj5JSUl8/etf5+6778YwDLONYRgsWLCAQYMGkZSURGFhITt27Ig6zr59+5g5cybp6elkZmYye/ZsGhoaotq8++67fOMb38DtdpOXl8eiRYti/XG6nVuVWhEREZEui3mo/d3vfsejjz7KI488wrZt2/jd737HokWLePjhh802ixYt4qGHHmLJkiVs2rSJlJQUioqKaG5uNtvMnDmTrVu3UlJSwqpVq9iwYQM33HCDud/j8TB58mSGDh1KWVkZ99xzD3fddRePPfZYrD9St4rcUUyVWhEREZHOs8f6gBs3buSSSy5h6tSpAAwbNownn3ySN954AwhXaR944AF+9rOfcckllwDw17/+lezsbFauXMkVV1zBtm3bWLNmDZs3b2bChAkAPPzww1x00UX8/ve/Jzc3l2XLluHz+fjLX/6C0+nkpJNOory8nPvuuy8q/CY6845iqtSKiIiIdFrMK7VnnXUWa9eu5YMPPgDgnXfe4d///jdTpkwBoLKykurqagoLC83XZGRkMHHiREpLSwEoLS0lMzPTDLQAhYWFWK1WNm3aZLaZNGkSTqfTbFNUVERFRQX79+9vt29erxePxxO1xJs5pZcqtSIiIiKdFvNK7R133IHH42HkyJHYbDaCwSC//vWvmTlzJgDV1dUAZGdnR70uOzvb3FddXc3AgQOjO2q3079//6g2+fn5hxwjsq9fv36H9G3hwoX84he/iMGnjB1zSi9VakVEREQ6LeaV2meeeYZly5axfPly3nrrLZ544gl+//vf88QTT8T6rTps/vz51NfXm8uuXbvi3SVVakVERERiIOaV2ltvvZU77riDK664AoAxY8awc+dOFi5cyKxZs8jJyQGgpqaGQYMGma+rqanh1FNPBSAnJ4fa2tqo4wYCAfbt22e+Picnh5qamqg2kfVImy9zuVy4XK6uf8gYUqVWREREpOtiXqk9ePAgVmv0YW02G6FQuBKZn59PTk4Oa9euNfd7PB42bdpEQUEBAAUFBdTV1VFWVma2WbduHaFQiIkTJ5ptNmzYgN/vN9uUlJQwYsSIdoceJCqXIxJqVakVERER6ayYh9pp06bx61//mtWrV/PJJ5+wYsUK7rvvPi699FIALBYLc+fO5Ve/+hXPPfccW7Zs4ZprriE3N5fp06cDMGrUKC688EKuv/563njjDV577TXmzJnDFVdcQW5uLgBXXXUVTqeT2bNns3XrVp5++mkefPBB5s2bF+uP1K1ap/RSpVZERESks2I+/ODhhx/mzjvv5Ec/+hG1tbXk5ubyX//1XyxYsMBsc9ttt9HY2MgNN9xAXV0d55xzDmvWrMHtdpttli1bxpw5c7jggguwWq3MmDGDhx56yNyfkZHByy+/THFxMePHj2fAgAEsWLCgV03nBa1TeqlSKyIiItJ5FqPtrb6OMR6Ph4yMDOrr60lPT49LH3btO8g3Fr2C22Fl+91T4tIHERERkUR1tHkt5sMPpGPaVmqP4d8vRERERLpEoTbOIlN6AfiCGoIgIiIi0hkKtXEWmdILNK5WREREpLMUauPMYbNgtYSfezVXrYiIiEinKNTGmcViwdVSrdVdxUREREQ6R6E2AbhbxtXqrmIiIiIinaNQmwBUqRURERHpGoXaBKBKrYiIiEjXKNQmAFVqRURERLpGoTYBqFIrIiIi0jUKtQnA1eauYiIiIiLScQq1CcBlD58Gb0CVWhEREZHOUKhNAG5VakVERES6RKE2AahSKyIiItI1CrUJQJVaERERka5RqE0AqtSKiIiIdI1CbQJQpVZERESkaxRqE4DmqRURERHpGoXaBKA7iomIiIh0jUJtAohUar2q1IqIiIh0ikJtAlClVkRERKRrFGoTgMbUioiIiHSNQm0CUKVWREREpGsUahOAKrUiIiIiXaNQmwBckXlqdfMFERERkU5RqE0A5h3FdPMFERERkU5RqE0AblVqRURERLpEoTYBqFIrIiIi0jUKtQnArNTqQjERERGRTlGoTQBmpVZTeomIiIh0ikJtAohUar2BEIZhxLk3IiIiIr2PQm0CiIRaULVWREREpDMUahNAZPgB6GIxERERkc5QqE0ADpsVm9UCaFovERERkc7ollD72Wef8d3vfpesrCySkpIYM2YMb775prnfMAwWLFjAoEGDSEpKorCwkB07dkQdY9++fcycOZP09HQyMzOZPXs2DQ0NUW3effddvvGNb+B2u8nLy2PRokXd8XF6hKb1EhEREem8mIfa/fv3c/bZZ+NwOHjxxRd5//33uffee+nXr5/ZZtGiRTz00EMsWbKETZs2kZKSQlFREc3NzWabmTNnsnXrVkpKSli1ahUbNmzghhtuMPd7PB4mT57M0KFDKSsr45577uGuu+7isccei/VH6hG6AYOIiIhI51mMGF9uf8cdd/Daa6/xr3/9q939hmGQm5vLT37yE2655RYA6uvryc7OZunSpVxxxRVs27aN0aNHs3nzZiZMmADAmjVruOiii/j000/Jzc3l0Ucf5ac//SnV1dU4nU7zvVeuXMn27dvbfW+v14vX6zXXPR4PeXl51NfXk56eHssvQ4cVLFzLnvpmnp9zDmMGZ8S1LyIiIiKJwuPxkJGRccS8FvNK7XPPPceECRP4zne+w8CBAxk3bhx/+tOfzP2VlZVUV1dTWFhobsvIyGDixImUlpYCUFpaSmZmphloAQoLC7FarWzatMlsM2nSJDPQAhQVFVFRUcH+/fvb7dvChQvJyMgwl7y8vJh+9q5QpVZERESk82Ieaj/++GMeffRRTjzxRF566SV++MMf8uMf/5gnnngCgOrqagCys7OjXpednW3uq66uZuDAgVH77XY7/fv3j2rT3jHavseXzZ8/n/r6enPZtWtXFz9t7ETG1OquYiIiIiIdZ4/1AUOhEBMmTOA3v/kNAOPGjeO9995jyZIlzJo1K9Zv1yEulwuXyxXXPhyOK3IDBl0oJiIiItJhMa/UDho0iNGjR0dtGzVqFFVVVQDk5OQAUFNTE9WmpqbG3JeTk0NtbW3U/kAgwL59+6LatHeMtu/Rm7gjlVoNPxARERHpsJiH2rPPPpuKioqobR988AFDhw4FID8/n5ycHNauXWvu93g8bNq0iYKCAgAKCgqoq6ujrKzMbLNu3TpCoRATJ04022zYsAG/32+2KSkpYcSIEVEzLfQWqtSKiIiIdF7MQ+3NN9/M66+/zm9+8xs+/PBDli9fzmOPPUZxcTEAFouFuXPn8qtf/YrnnnuOLVu2cM0115Cbm8v06dOBcGX3wgsv5Prrr+eNN97gtddeY86cOVxxxRXk5uYCcNVVV+F0Opk9ezZbt27l6aef5sEHH2TevHmx/kg9QpVaERERkc6L+Zja008/nRUrVjB//nx++ctfkp+fzwMPPMDMmTPNNrfddhuNjY3ccMMN1NXVcc4557BmzRrcbrfZZtmyZcyZM4cLLrgAq9XKjBkzeOihh8z9GRkZvPzyyxQXFzN+/HgGDBjAggULouay7U1UqRURERHpvJjPU9ubHO28Zz3h1mff4dmyT7ntwhH86NwT4toXERERkUQRt3lqpXPMeWpVqRURERHpMIXaBBGZp9arMbUiIiIiHaZQmyDcGlMrIiIi0mkKtQlClVoRERGRzlOoTRAaUysiIiLSeQq1CcLlUKVWREREpLMUahOE265KrYiIiEhnKdQmiEilttmvSq2IiIhIRynUJghXS6XWG1ClVkRERKSjFGoThFuVWhEREZFOU6hNEKrUioiIiHSeQm2CUKVWREREpPMUahOEKrUiIiIinadQmyBUqRURERHpPIXaBBG5o5hX89SKiIiIdJhCbYJw2cOnwhcMEQoZce6NiIiISO+iUJsgIpVa0LhaERERkY5SqE0QkUotgDegcbUiIiIiHaFQmyDsNit2qwWAZo2rFREREekQhdoEEqnWqlIrIiIi0jEKtQkkMq5WlVoRERGRjlGoTSCtoVaVWhEREZGOUKhNIK3DD1SpFREREekIhdoE4lKlVkRERKRTFGoTiCq1IiIiIp2jUJtA3I7w6VClVkRERKRjFGoTiMseHn6gSq2IiIhIxyjUJhBVakVEREQ6R6E2gWhKLxEREZHOUahNILpQTERERKRzFGoTSKRS61WlVkRERKRDFGoTiCq1Il23dXc9Nz75Np980RjvroiISA9SqE0gGlMr0nVPbPyE59/ZzZObq+LdFRER6UHdHmp/+9vfYrFYmDt3rrmtubmZ4uJisrKySE1NZcaMGdTU1ES9rqqqiqlTp5KcnMzAgQO59dZbCQQCUW1effVVTjvtNFwuFyeccAJLly7t7o/TrVSpFem6nXsPAlD5uSq1IiLHkm4NtZs3b+aPf/wjp5xyStT2m2++meeff55nn32W9evXs3v3bi677DJzfzAYZOrUqfh8PjZu3MgTTzzB0qVLWbBggdmmsrKSqVOnct5551FeXs7cuXO57rrreOmll7rzI3UrVWpFum7XvpZQq+EHIiLHlG4LtQ0NDcycOZM//elP9OvXz9xeX1/Pf//3f3Pfffdx/vnnM378eB5//HE2btzI66+/DsDLL7/M+++/z9/+9jdOPfVUpkyZwt13383ixYvx+XwALFmyhPz8fO69915GjRrFnDlz+Pa3v83999/fXR+p27nMUKtKrUhn+AIh9niaAdi57yChkBHnHomISE/ptlBbXFzM1KlTKSwsjNpeVlaG3++P2j5y5EiGDBlCaWkpAKWlpYwZM4bs7GyzTVFRER6Ph61bt5ptvnzsoqIi8xjt8Xq9eDyeqCWRtA4/UKVWpDM+q2vCaMmxvkCI3fVN8e2QiIj0mG4JtU899RRvvfUWCxcuPGRfdXU1TqeTzMzMqO3Z2dlUV1ebbdoG2sj+yL6vauPxeGhqav8/soULF5KRkWEueXl5nfp83cWtSq1Il0SGHkRoCIKIyLEj5qF2165d3HTTTSxbtgy32x3rw3fJ/Pnzqa+vN5ddu3bFu0tRVKkV6ZqqL4VaTeslInLsiHmoLSsro7a2ltNOOw273Y7dbmf9+vU89NBD2O12srOz8fl81NXVRb2upqaGnJwcAHJycg6ZDSGyfqQ26enpJCUltds3l8tFenp61JJIVKkV6Zpd+79cqT14mJYiItLXxDzUXnDBBWzZsoXy8nJzmTBhAjNnzjSfOxwO1q5da76moqKCqqoqCgoKACgoKGDLli3U1taabUpKSkhPT2f06NFmm7bHiLSJHKM3UqVWpGs+3RceenTCwFQAKr9oiGd3RESkB9ljfcC0tDROPvnkqG0pKSlkZWWZ22fPns28efPo378/6enp3HjjjRQUFHDmmWcCMHnyZEaPHs3VV1/NokWLqK6u5mc/+xnFxcW4XC4AfvCDH/DII49w2223ce2117Ju3TqeeeYZVq9eHeuP1GNUqRXpmsjwg2+cOIAPaxv4ZK8qtSIix4q43FHs/vvv5+KLL2bGjBlMmjSJnJwc/vGPf5j7bTYbq1atwmazUVBQwHe/+12uueYafvnLX5pt8vPzWb16NSUlJYwdO5Z7772XP//5zxQVFcXjI8WE26FKrUhXRIYfTBp+XHh930H8Qf2SKCJyLIh5pbY9r776atS62+1m8eLFLF68+LCvGTp0KC+88MJXHvfcc8/l7bffjkUXE4LLHq7UelWpFekwT7OfuoN+AE4f1h+3w0qzP8Sn+5vIH5AS596JiEh3i0ulVtoXqdQ2q1Ir0mGR6byyUpykuuwMywoHWc2AICJybFCoTSCRSq0/aBDUnZBEOiQSagf3TwYwq7Oaq1ZE5NigUJtAIpVa0LhakY7a1TLzwZCWUDtMoVZE5JiiUJtAIpVa0LhakY6KXCSW1y88T3WkUvvJXoVaEZFjgUJtArFZLThsFkDjakU6KjKdV56GH4iIHJMUahOM2665akU6IzKm1hx+0HKh2Gd1TTT79UuiiEhfp1CbYFyaq1akw0Ihg137w2Nq8/qFQ+2AVCdpLjuG0Rp4RUSk71KoTTAuVWpFOuzzBi++QAib1cKgTDcAFotFF4uJiBxDFGoTjFmp1Z9LRY5aZDztoAw3DlvrP2sKtSIixw6F2gRjjqkNqFIrcrS+PJ42QjMgiIgcOxRqE4wqtSIdZ8580O/LoTa8rkqtiEjfp1CbYFSpFem4yI0X8vonRW2PzICgUCsi0vcp1CaYyF3FNAWRyNEzb7xwmOEHNR4vB32BHu+XiIj0HIXaBBOZ/cCrSq3IUdu1r/1Qm5nspF+yA4BPvtC0XiIifZlCbYJxa0ytSId4A0GqPc3AoReKgWZAEBE5VijUJhhVakU65rP9TRgGJDlsZKU4D9mvGRBERI4NCrUJRmNqRTomciexIf2TsVgsh+zP18ViIiLHBIXaBONyqFIr0hHmdF5fmvkgQsMPRESODQq1CcZtV6VWpCM+bQm1g/sdOp4W2gw/UKgVEenTFGoTTKRSq1ArcnQi03m1d5EYtFZq9zb6qG/y91i/RESkZynUJhhXS6VWww9Ejk7VYabzikh12TkuzQWoWisi0pcp1CYYtyq1Ih0SuZvY4Sq1oBkQRESOBQq1CUaVWpGjV9/kN4cUDO7X/oVioBkQRESOBQq1CUaVWpGjF7mT2IBUJyku+2HbaQYEEZG+T6E2wahSK3L0dh1h5oMIzYAgItL3KdQmmNZKrUKtyJFEZj443EViEfltKrWGYXR7v0REpOcp1CaYSKj1aviByBG1XiR2+PG0AEOzwqHX0xxgX6Ov2/slIiI9T6E2wWj4gcjRM6fzOsLwA7fDxvGZ4eCrGRBERPomhdoEowvFRI7ekW680NawAeE2lV8c7NY+iYhIfCjUJhhVakWOTihk8GnL8IMjjakFGGZO69XQrf0SEZH4UKhNMKrUihyd2gNefMEQNquFQRnuI7ZvnQFBlVoRkb5IoTbBRCq1gZBBIKhqrcjhRMbT5ma6sduO/E9ZvuaqFRHp0xRqE0ykUgsagiDyVXYd5UViEcPa3CpX03qJiPQ9MQ+1Cxcu5PTTTyctLY2BAwcyffp0Kioqoto0NzdTXFxMVlYWqampzJgxg5qamqg2VVVVTJ06leTkZAYOHMitt95KIBCIavPqq69y2mmn4XK5OOGEE1i6dGmsP06Pi1RqQUMQRL5KRy4Sg3D4tVktHPQFqT3g7c6uiYhIHMQ81K5fv57i4mJef/11SkpK8Pv9TJ48mcbG1j/53XzzzTz//PM8++yzrF+/nt27d3PZZZeZ+4PBIFOnTsXn87Fx40aeeOIJli5dyoIFC8w2lZWVTJ06lfPOO4/y8nLmzp3Lddddx0svvRTrj9SjrFYLTpsuFhM5EnM6r6MMtU67lcH9wtN6ffy5hiCIiPQ1h79ZeietWbMman3p0qUMHDiQsrIyJk2aRH19Pf/93//N8uXLOf/88wF4/PHHGTVqFK+//jpnnnkmL7/8Mu+//z7//Oc/yc7O5tRTT+Xuu+/m9ttv56677sLpdLJkyRLy8/O59957ARg1ahT//ve/uf/++ykqKor1x+pRLocVXzCkSq3IV+jIzAcRw7JS2Ln3IJ/sbaTg61nd1TUREYmDbh9TW19fD0D//v0BKCsrw+/3U1hYaLYZOXIkQ4YMobS0FIDS0lLGjBlDdna22aaoqAiPx8PWrVvNNm2PEWkTOUZ7vF4vHo8naklELnvLXcVUqRU5rNYbL3z13cTaap0BQZVaEZG+pltDbSgUYu7cuZx99tmcfPLJAFRXV+N0OsnMzIxqm52dTXV1tdmmbaCN7I/s+6o2Ho+HpqamdvuzcOFCMjIyzCUvL6/Ln7E7uB3h06JKrUj7mv1Bag40A0c/phZaQ+3HCrUiIn1Ot4ba4uJi3nvvPZ566qnufJujNn/+fOrr681l165d8e5Su3QDBpGv9lldE4YByU4b/VOcR/26YarUioj0WTEfUxsxZ84cVq1axYYNGxg8eLC5PScnB5/PR11dXVS1tqamhpycHLPNG2+8EXW8yOwIbdt8ecaEmpoa0tPTSUpq/8+RLpcLl8vV5c/W3XQDBpGv1nY6L4vFctSv+1pLqN257yDBkIHNevSvFRGRxBbzSq1hGMyZM4cVK1awbt068vPzo/aPHz8eh8PB2rVrzW0VFRVUVVVRUFAAQEFBAVu2bKG2ttZsU1JSQnp6OqNHjzbbtD1GpE3kGL1Za6hVpVakPbv2d/wiMYDczCScNiu+QIjdde0PUxIRkd4p5qG2uLiYv/3tbyxfvpy0tDSqq6uprq42x7lmZGQwe/Zs5s2bxyuvvEJZWRnf//73KSgo4MwzzwRg8uTJjB49mquvvpp33nmHl156iZ/97GcUFxebldYf/OAHfPzxx9x2221s376dP/zhDzzzzDPcfPPNsf5IPa51+IEqtSLtMSu1/Y/+IjEAm9VivuaTvRqCICLSl8Q81D766KPU19dz7rnnMmjQIHN5+umnzTb3338/F198MTNmzGDSpEnk5OTwj3/8w9xvs9lYtWoVNpuNgoICvvvd73LNNdfwy1/+0myTn5/P6tWrKSkpYezYsdx77738+c9/7vXTeUFrpdarSq1IuyKhtiMXiUXkD0gFNK5WRKSvifmY2qO5/aTb7Wbx4sUsXrz4sG2GDh3KCy+88JXHOffcc3n77bc73MdEp0qtyFer6uAtctvKHxB+jWZAEBHpW7p9nlrpOI2pFflqZqU2q+OhVjMgiIj0TQq1CUiVWpHDqz/ox9McADBve9sR5g0Y9h6Mab9ERCS+FGoTkCq1Ioe3a384jA5IdZLs7PgIqkiordp3EH9QP2MiIn2FQm0CcumOYiKH1TrzQceHHgBkp7lxO6wEQwaf7te0XiIifYVCbQJy2VtmP9AdxUQO0ZWLxACsVgvDsjSuVkSkr1GoTUBuVWpFDisy/KAz03lFRIYgaAYEEZG+Q6E2AalSK3J4VfsidxPr+EViEZoBQUSk71GoTUCq1Ioc3qddHFMLbWdAUKgVEekrFGoTkCq1Iu0Ltbm4q7NjaqHN8IPPFWpFRPoKhdoEpEqtSPtqDjTjC4awWS0MynB3+jiRC8V21zfp50xEpI9QqE1A7pZKbbMqtSJRdrWMpz0+Mwm7rfP/fA1IdZLmsmMYrVOEiYhI76ZQm4Ai89R6VUESiWJO59WFi8QALBaLebGYZkAQEekbFGoTUOSOYhpTKxItUlXtynReEZoBQUSkb1GoTUAuuyq1Iu2JhNrBXbhILEIzIIiI9C0KtQkoUqnVmFqRaJEbL3RlOq+I/AHhY2gGBBGRvkGhNgGpUivSvqpYDj/IUqVWRKQvUahNQKrUihyq2R+kxuMFIK9f1y4Ug9bhBzUeL43eQJePJyIi8aVQm4AiU3oFQwb+oIKtCMBndeHpvFKcNvqnOLt8vMxkJ/2SHYCqtSIifYFCbQKKTOkFmgFBJKKqze1xLRZLTI7ZOgOC5qoVEentFGoTUGRMLeiuYiIRn+6L3UViEZoBQUSk77DHuwNyKIvFgtNuxRcI9elKrWEYlH68l/2NfsYNySQ3s+vjJKXvMiu1MZjOKyK/5WIxzYAgItL7KdQmKHdLqO2rlVpPs5+frniP59/ZbW7LSXdz2tBMThvSj3FD+nHy8em4WsYXi0RukdvVu4m1NUyVWhGRPkOhNkG5HDZoDuD1971K7VtV+/nxk2/z6f4mbFYLJw5MZUdtA9WeZl7YUs0LW6oBcNqsnHR8ekvIDYddVXOPXbGczisiMvxgy2f1XPOXN8hOc5Gd7iY7w20+z8lwk5XixG7TaC0RkUSmUJug3C0XizUH+k6lNhQyeHT9R9xX8gHBkMHgfkk8dOU4ThvSj4O+AO9+Ws9bVft5a2cdb1ftZ2+jj7er6ni7qs48xoBUJ6kuOw6bNbzYrThtltZ1mxWnPbzutFlJT3KQ0xJMcjLc5KS7GZjuUgW4lzEMw7ybWCzH1J4wMJV+yQ72H/Sz4YPPD9vOaoEBqeGQe1yaC7fDGv09F/ketH9p3WbFZrVgtQCW8KOFlkdLeKiR1WLBAlitYLVYsFutOGyW8LHaPHfarNhtrd/bDpuV/ilOnHaFbRERUKhNWJFpvfrK8IMaTzM3P13Oxo/2AnDxKYP4zWVjSHeHp1RKdto582tZnPm1LCAcYqr2HTRD7ltV+9lefYAvGnx80eDrcn+yUpxmFS4SdnPS3RyX7mJgmovj0lxkpbiwWWNzlb10TX2TnwMtc8nGckyt22Fj7U/O5b3P6qnxNFN7wEt1fTM1nmZqDnipqW/m8wYvwZBB7QEvtQe8MXvvWEhz2Zl8Ug7Txg7i7BMG4FA1WUSOYQq1CSoyrVdfuFBs7bYabnn2HfYf9JPksPGLS07iO+MHf+W0TBaLhaFZKQzNSuHScYMBOOgL8FFtI95AEF8whD9o4A+E8AdDrevBlvVAeFvdQT976pupqW+m2hNefIEQext97G308f4ez2H7YLVAVmpryB2Y5mJgmtt8npHkIMlpCy+O8OJuea5wEVuR8bQDUl0kOWNbZe+f4mTS8OMOuz8YMtjb6KWm3kuNp5kvGrz4Wr7Hor7ngiH8geh1XyBEyDAwDMxHg/AvbeY2IGSEt4UMA3/QINDm+9kXDBH40vd2IGTgC4Q44A3wv299yv++9Sn9kh1MGTOIaafkckZ+f/1CJiLHHIXanmIY8MzVMPRsGPOfkJL1lc0jldp43Co3FDI46A/S6A3Q4A1w0BskM9nB4H5JHZof1BsIsvCF7Szd+AkAowel8/BV4/j6calf9ebQUA37d0LdzqjH5LqdjGn8AjKOh3750P9rLUvL88whYHd9ZZ8Mw2D/Qb9ZjdvTEnYjobf2gJfPD3jZ2+glZMDnLesd5bBZcLcE3SSnjWSnnUEZbo7PTOL4fknm4+DMJAakurAqgHylXfsj42mPMKY66Iddm+Czt8DmAEcSOFLAmfyl55ElCZwp4baHYbNaGJjmZmCamzFkxPJjdUkoZPBW1X6ef2c3q7fs4YsGH8s3VbF8UxUD01xMPWUQ3xqby6l5mTGb11dEJJEp1PaUXW/AtufDy8t3wvAiGPddOKGw3f9Qu6tS2+wP8uJ7e3i14nMONIdDa6M3wEFfMOp5e9LcdkYNSmd0ZMlN58Ts1HbHp35Y28CPn3zbrIR+/+xh3DFlZGtbw4DPK6ByPXy+vTW81u2C4BFC5N4Pw8uXWayQPrg15PbPh7RcSMoEdyYkZWJxZ9DfnUn/3HD/DycQDLGv0WeG3NoDzS2PXvPxQLOfJn+QJl+IJl+AJn+QkBF+fbjKFuBAc+vtV7cdpirstFkZlNkSeFvC7oBUF2lue8viIM1tJ9UVfp7qsh9zVbiqrxpPW/8ZfFgCO0rg4/XgOxCDd/zS1zcqFFrC32tWW/jRYgsPiDWff2m71Q5WR/jn3GoHm7PNc0frPpsDbC5IGQCp2ZCWA6kDIbXl0Z0R1Q+r1cKEYf2ZMKw/d148mk2V+3iufDcvvreH2gNeHn/tEx5/7RMG90ti2thc/mN0NlaLhf0HfdQd9LG/0U9dkz/8/GD4se6gn/0HfdQf9ONyWMkfkMKwrBTyj0shv+VxWFaKeStvEZFEYjEMw4h3J+LF4/GQkZFBfX096emHDzgx0bQftvwd3v4b7Clv3Z5yHJxyOZw6E7JHm5tnL93M2u21/G7GGC4/fUjX3tsw+PSj93j7tZfwVpZyUqiCEyy7acJJI0k0GEk0kMSBlscGI4lG3DSQhM+eit+WwsfedN4PDuYzIwujzT077FYLXz8uldG54aA7alA6u/Yf5JfPv0+TP0j/FCf3fPsULhiVDQ218PGr8NEr4ccDu9vvr8UGGYOh39Bw9TVzWMvzoeH/8Os/hX0fw/7K8OO+yvDi78C0TI5kM+jizgwHhqRMcKWBMzX8GPW85dHZ5rkjJRxazC+zgS8YotkXoskf5GBL0G32B/E0B9hT18xndQf5bH8Tn9U18dn+Jqo9zWYQ7ogUp6017LrtJDttJDkij5HqcHhJctpJckSetwyTiAyXcFhxO2y4HFZzeyIOnfjpii0s21TFnPNO4JYL8qGqNBxkP1wLte9HN07OCv9FxOYA38Hw94W/qeV5ZGkCXyMYvWjMut3dEnKzW5eBo2DEReG/XrTwBUL8a8fnPP/Obl5+v+awv6R2RW6G2wy4+QPCw4Qyk/XLl4h0j6PNawq1PRVq26rZCuXL4d2nobHNFdeDTg1Xb0+ewY9WVPLClmqmn5rL7HO+xqhBaUc/pZDvIOx+m2DV6+zd9i/cNW+RHqqPSdf9tmRq3PnsMPJ4symHcu8gPgjl8TkZfLm6dW5+CvcXNNFvz7/DIbbmveiD2d0wpAAGTwgH1khwTT8ebB38I4JhhEOzGXRbwm5jLTTVQXMdNNWDNzZfB5PNGf4Ttj0JHO5wWLa7W/7UndT63O4OD42wu8OvsbvA5iRodeLxW9nvhb3NFj5vgs+bYJ/XSl3AwT6/g30+G1/47NR6bdQHnIS6+UaANqvFDLwue2vwjYRet8OKy2HDfci+SEC24bZbW9q2bm/b3u2wkeIKD8v4SqEQNO1j/l//ifXTTfxo8Cccv/8N8DW0trFY4fgJ4b96nFgIg8ZF/bJxWIYBQV843IYiwc+I3t+60uZpqHUJBdt5HoxeDwXCwyJCfggGWh59bZ632RdogobPoaEmemk+wvdt7mkw6mIYOQ2OG25ubvIFWbe9luff2c2myr0kO+1kJjtaFif9kh1kJjnJTHbQL9lJvxQHGS3rB71BKvc2Uvl5I5VfNFC59yCVnzfgafPXhyNJdtrMoJvqdpDe8rx/ipPczCQGZbgZlJFEbmb4gk3NSiIi7VGoPQpxC7URQT98+M9w9faDNeH//ABsTramnc3DtWNpIAkbIVLsBicOTGb4ccmcMMBNfv8knNbIf5zB8LG++AB2bcKo3oIlFP0fj9dwsNM9HOewAvLGnott0Cnh9/MeiF58Bw7d1uwJDw34vCL8n287muwZ7HIMY6s/l5pAKhdnfsLxB97BEvzSTAU5p8DXz4OvnRcOtA53d3xlDy8UDAeE5rrWsNtc3/rc2xAOTObXI/K8oc3XpyGuFT7D5iJkTyZoTyJgc+O3JhG02AhgJ4CVgGHDjxW/YcNv2PAZVnwhGz7Dgjdkw2vYaA5Z8YZsNAWtNIesNAVt+LATwIYfO35s+A07fux4cdCME68RfmzGGd5mOFv34Yiq4IOBgyB2Ai2P4cVBALsl/NyNn8GuRk5IbmKou5Hj7QcYaK0nM1RHamA/Lu8XWA7uxdLe1zrluHCIPaEQvn4+JPfvsa9/XPibwr+0RULugWo4sAc++Xd4aFPb0D1gOIy8OBxyc0/70tCJIwgFw8ev2xX+Hk8eEK58J2WC1WaOSa/8ooGPP2/kk72NVH7RyK59TRxo9tPgDeBpDuDr5LCpAalOBmWEw24k9EbCrt1qwW4LT3kWfgwvLn897qbduBt342zYjcXuIJA1nGDWSCzJWS3Tp4WnUbNGplAzp0+zaCiFSC+gUHsU4h5q22r8ArY8C+XLoHpLlw9XbfSjLHQi2+2jGDB6EuefW0jecZldO2jQH66A1r4PtdtaH/d9HK5ItSd9MHz93HCI/dq54eEDvZ1hhENG5M/YgeaW9aZwpc3fHN4X2R6IrPvC44UPeWw+dJu/Ofxn88ifzH2NRAWXBBSwODAAmxHESmzHgu83UtlhHM+Is6eTMeai8C9HR1ONPRYcqIGK1bBtFVRuiP7FM/14GDk1HHKHnh3+Rbb+U6ivCj/W7YL6XS3Pq8Cz+zC/uFrCvzgkZ7W/uDPC38ctvwwGmw8QaPIQaD6A0XwAw3sAi68Bq78Bm7+REFYOWNOpJ5UvginU+JPYG0qlzkhhP2nUtzzWGSkcxM1ASx25fEGuZS+5li8YbIk830uy5fBj8GuNTCpCg9lhDOYDYzAftDw/QOvYbLfDSlaKi6xUJ1kpTvqnuBiQ6qR/ipOsVBdZKU6yWtb7JTtJdtric+GdrzF8/UHttvB5yzoBjj8tfNGsfhakj1OoPQoJFWrb2vNueHjCJ/8CwLBYaQ5aaPAZ1PsM6ptDNAUghJUANsIRwspuI4u3QidSFhrO4KEnMrNgKBeenNP9f9LzN4erxJGge6Aajh8frshmndCxSpG0zzDCoaHtuFBfY2uwDvrDgcX8E3fL81Cg9c/cbZ8HfeHXBFueh9o8D7b5k3jA1xK6WxZ/2+dNHatYW6zmRVGG1Y5hc+F39aPR0Z86az++MDLYHUilypvKhweT+ehgMp8bGewjjQB20t123rrzP3Rnr6/SXA8fvAzbn4cd/4weZ253h8/bkVhsrUOADu498tCHBPAFmVSTxW5jAC58nMAujrd8cdj2nxlZ7AgN5iMjl0ZcBIzIXylsbf5aYW/5q0d4WwAbzThpsiQTcqZicaVidaXjSE4jOSmJNLed9JYhFpHx7k576w06XObz1ptpmOst+512Ky5LCKenEtvnbQoHNVth/ye0+4utKwNyTw0H3NzTIHdc+JqE3v7vru9g+DM4dBdJUag9Kgkbao/AMAw+3d/EG5X7eHPnPt6o3MdHnzeS5rJz2WnHc9XEoYzISYt3N+VYEBkHGvCGQy7Gl670d7Re/d/BalKzP8ie+uaWC+sOclJuBicfnzhTaiU8f1N4LPu2VVDxAjTtC293pEBmHmTkhcNPZh5kDGl9npoTPaY96IeD+8IB11y+iN7WXN8yPVrLhZTO1DaPbS+6TA23CQXCF8827Qs/Htz3pfX9reveBkjLDvcvo02/I0v68e0PY/IeCA+Zqn0fardjfL4NardhObAn5l9qr+GgATeNhptGkjhAEgcNN35sBLERaCk8BLARNMKP4XVry34bAy37GWH5lK9ZduOytD9ueb8lg522oey1D2RI8FOG+j/CyaGV9UZ7P2rSTuKL9JPYl3kSB13ZBP1eQgEvRqAZw++FgBcj4MMSbP1LkSXkwxbyE7InYTiSsThTsThTsLlTsLlTsSel4UpKw5GUjjsljaSkFJJddvNi08jYeYfNcvhqdsAXPYTGXFrWPS3PI9c/pEemcGw7jWPL7DYu/T93rDhmQu3ixYu55557qK6uZuzYsTz88MOcccYZR/Xa3hpq2xOZgkfjw0TkEMFA+CLK5CxI6tf7q3hd0bS/Nezu+zj8C5l5sZ6/nYv6wn/lMII+DF8ToZax9lZfA9YjTT/YSY2Giw+MPLaH8vjAGMx2YwgfhAaz90vzJNsJMMLyKadYP+IUy8eMtX7McMsu7JaeuWlPyLDgw46BBQMLoZZHCP8lMfJ9ZrQ8txEizYjFlHthza4BNKUOoTl9KP7UPKw2GzZC2Ahht4RafmUIr1uNIDaLgdUIYDXCPe0Qu7t1bmtHUpvnX35MCk/r9+W/fLX7FzFfeBy7zd5yEbEL7M42FxS7w+s2V+tzq73lglSjZdif0Wbd+NJ6ZL/R+njINlrXLZaWIkTbgsSX120tRYqWbT30b8kxEWqffvpprrnmGpYsWcLEiRN54IEHePbZZ6moqGDgwIFHfH1fCrUiItLDgv42F5S2ucjU1xAeHhT0h4fohIItQ4Iij4HWi3wjs2MkZRIcMBJv/1F4U3LxBsPTs3kDQbyBEN5AKGrdZ66Ht0WeB72NZHoqGHjgfQY1vM/xTdtJDh4gYHUStDgIWp2EbE5CVhchmxPD5sSwOjEiQcrmMKe8swYOYvMfxBY8iCPYhCPYhNNowm10Lcz7DBu19KPGaGdp2V5r9MNOgGGWGoZYahhmqWGotYZhlmqGWmrIssQuHEvn1I/+Lhn/ubhH3uuYCLUTJ07k9NNP55FHHgEgFAqRl5fHjTfeyB133HFIe6/Xi9fb+sPo8XjIy8tTqBURETlaoWDruP6gDwwDwwjhCwTx+YP4AkG8/kA4bPv9+PytYfygM4uDtjT8IYt56+fILaEDwRC+lttEm7eDDobM26H7gy3rwRAOv4f+3t0M8H3GwMBusgK1GIaB37DgN6zhJWTBb1jwhawEsRIwrOY1KKEv32DlK1gAF36SLF7c+EjCS5Il/OjGR5LFS1LLdpfFj50gvpbZY/ztzCoTIDzbjB87IazYCeLEjws/TosfJ4Hwc/w4LeHnkXUbIbMi3rY6Hv480euGWY9ufW608xzAMCxYLEa4yk0AOyFsBHEQxEYQp+XQ6ydeHzCDM+f8pevfT0fhaENtr72jmM/no6ysjPnz55vbrFYrhYWFlJaWtvuahQsX8otf/KKnuigiItL3WG2tY6VbhINfeElEwVA4OEdCcjBkEDQMQkb4ltPBkEHIiCzh9sGQEZ7O2mgJ2pEA3hKym4IhPC2B3N8SxP0toTxoGOHjGgbBEIQMwzxm5Hnk0WgZBRApMRotwwLC24yofSFz3SDUctyQ0bIe+TxGS79DBgatxw8fs+37GV963/DKl/sSGdlgMYItQzn82Iwgk0fmcWYPnb+j1WtD7RdffEEwGCQ7Oztqe3Z2Ntu3b2/3NfPnz2fevHnmeqRSKyIiIn2XzWrBZrXpupM+rteG2s5wuVy4XIn6e6SIiIiIdFavnfBxwIAB2Gw2ampqorbX1NSQk5MTp16JiIiISDz02lDrdDoZP348a9euNbeFQiHWrl1LQUFBHHsmIiIiIj2tVw8/mDdvHrNmzWLChAmcccYZPPDAAzQ2NvL9738/3l0TERERkR7Uq0Pt5Zdfzueff86CBQuorq7m1FNPZc2aNYdcPCYiIiIifVuvnqe2q3TzBREREZHEdrR5rdeOqRURERERiVCoFREREZFeT6FWRERERHo9hVoRERER6fUUakVERESk11OoFREREZFeT6FWRERERHo9hVoRERER6fV69R3Fuipy3wmPxxPnnoiIiIhIeyI57Uj3CzumQ+2BAwcAyMvLi3NPREREROSrHDhwgIyMjMPuP6ZvkxsKhdi9ezdpaWlYLJZufz+Px0NeXh67du3SbXl7OZ3LvkPnsu/Quew7dC77jlicS8MwOHDgALm5uVithx85e0xXaq1WK4MHD+7x901PT9cPaR+hc9l36Fz2HTqXfYfOZd/R1XP5VRXaCF0oJiIiIiK9nkKtiIiIiPR6CrU9yOVy8fOf/xyXyxXvrkgX6Vz2HTqXfYfOZd+hc9l39OS5PKYvFBMRERGRvkGVWhERERHp9RRqRURERKTXU6gVERERkV5PoVZEREREej2FWhERERHp9RRqe8jixYsZNmwYbrebiRMn8sYbb8S7S3IUNmzYwLRp08jNzcVisbBy5cqo/YZhsGDBAgYNGkRSUhKFhYXs2LEjPp2Vw1q4cCGnn346aWlpDBw4kOnTp1NRURHVprm5meLiYrKyskhNTWXGjBnU1NTEqcdyOI8++iinnHKKeXeigoICXnzxRXO/zmPv9dvf/haLxcLcuXPNbTqfvcNdd92FxWKJWkaOHGnu76nzqFDbA55++mnmzZvHz3/+c9566y3Gjh1LUVERtbW18e6aHEFjYyNjx45l8eLF7e5ftGgRDz30EEuWLGHTpk2kpKRQVFREc3NzD/dUvsr69espLi7m9ddfp6SkBL/fz+TJk2lsbDTb3HzzzTz//PM8++yzrF+/nt27d3PZZZfFsdfSnsGDB/Pb3/6WsrIy3nzzTc4//3wuueQStm7dCug89labN2/mj3/8I6ecckrUdp3P3uOkk05iz5495vLvf//b3Ndj59GQbnfGGWcYxcXF5nowGDRyc3ONhQsXxrFX0lGAsWLFCnM9FAoZOTk5xj333GNuq6urM1wul/Hkk0/GoYdytGpraw3AWL9+vWEY4fPmcDiMZ5991myzbds2AzBKS0vj1U05Sv369TP+/Oc/6zz2UgcOHDBOPPFEo6SkxPjmN79p3HTTTYZh6OeyN/n5z39ujB07tt19PXkeVantZj6fj7KyMgoLC81tVquVwsJCSktL49gz6arKykqqq6ujzm1GRgYTJ07UuU1w9fX1APTv3x+AsrIy/H5/1LkcOXIkQ4YM0blMYMFgkKeeeorGxkYKCgp0Hnup4uJipk6dGnXeQD+Xvc2OHTvIzc3la1/7GjNnzqSqqgro2fNoj+nR5BBffPEFwWCQ7OzsqO3Z2dls3749Tr2SWKiurgZo99xG9kniCYVCzJ07l7PPPpuTTz4ZCJ9Lp9NJZmZmVFudy8S0ZcsWCgoKaG5uJjU1lRUrVjB69GjKy8t1HnuZp556irfeeovNmzcfsk8/l73HxIkTWbp0KSNGjGDPnj384he/4Bvf+Abvvfdej55HhVoROaYUFxfz3nvvRY33kt5lxIgRlJeXU19fz9///ndmzZrF+vXr490t6aBdu3Zx0003UVJSgtvtjnd3pAumTJliPj/llFOYOHEiQ4cO5ZlnniEpKanH+qHhB91swIAB2Gy2Q67yq6mpIScnJ069kliInD+d295jzpw5rFq1ildeeYXBgweb23NycvD5fNTV1UW117lMTE6nkxNOOIHx48ezcOFCxo4dy4MPPqjz2MuUlZVRW1vLaaedht1ux263s379eh566CHsdjvZ2dk6n71UZmYmw4cP58MPP+zRn0uF2m7mdDoZP348a9euNbeFQiHWrl1LQUFBHHsmXZWfn09OTk7UufV4PGzatEnnNsEYhsGcOXNYsWIF69atIz8/P2r/+PHjcTgcUeeyoqKCqqoqncteIBQK4fV6dR57mQsuuIAtW7ZQXl5uLhMmTGDmzJnmc53P3qmhoYGPPvqIQYMG9ejPpYYf9IB58+Yxa9YsJkyYwBlnnMEDDzxAY2Mj3//+9+PdNTmChoYGPvzwQ3O9srKS8vJy+vfvz5AhQ5g7dy6/+tWvOPHEE8nPz+fOO+8kNzeX6dOnx6/Tcoji4mKWL1/O//3f/5GWlmaO48rIyCApKYmMjAxmz57NvHnz6N+/P+np6dx4440UFBRw5plnxrn30tb8+fOZMmUKQ4YM4cCBAyxfvpxXX32Vl156Seexl0lLSzPHtUekpKSQlZVlbtf57B1uueUWpk2bxtChQ9m9ezc///nPsdlsXHnllT37cxnTuRTksB5++GFjyJAhhtPpNM444wzj9ddfj3eX5Ci88sorBnDIMmvWLMMwwtN63XnnnUZ2drbhcrmMCy64wKioqIhvp+UQ7Z1DwHj88cfNNk1NTcaPfvQjo1+/fkZycrJx6aWXGnv27Ilfp6Vd1157rTF06FDD6XQaxx13nHHBBRcYL7/8srlf57F3azull2HofPYWl19+uTFo0CDD6XQaxx9/vHH55ZcbH374obm/p86jxTAMI7YxWURERESkZ2lMrYiIiIj0egq1IiIiItLrKdSKiIiISK+nUCsiIiIivZ5CrYiIiIj0egq1IiIiItLrKdSKiIiISK+nUCsiIiIivZ5CrYiIiIj0egq1IiIiItLrKdSKiIiISK/3/wExVzf50pZz/QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9498129583135507\n",
      "RMSE:  9.713121414944831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 LAYERED LSTM WITH BOTH RETURN_SEQ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/558 [================>.............] - ETA: 5s - loss: 13928.7051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 25\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39m2LayerLSTM6432_v2.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Fit model with checkpointing\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_X, train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (test_X, test_y), callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', return_sequences= True,  input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('2LayerLSTM6432_v2.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 27\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score, mean_squared_error\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m r2 \u001b[39m=\u001b[39m r2_score(test_y, pred_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(test_y, pred_y))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mR2 score:\u001b[39m\u001b[39m\"\u001b[39m, r2)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[0;32m    785\u001b[0m     y_true,\n\u001b[0;32m    786\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m ):\n\u001b[0;32m    792\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Layered LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 20s 29ms/step - loss: 5037.4058 - val_loss: 681.5106\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 15s 27ms/step - loss: 1514.5847 - val_loss: 682.6987\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 936.0818 - val_loss: 468.7449\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 626.7081 - val_loss: 387.4768\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 383.7231 - val_loss: 317.8738\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 386.9725 - val_loss: 274.4425\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 285.8145 - val_loss: 242.0559\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 240.5510 - val_loss: 210.7982\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 245.4944 - val_loss: 193.7261\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 14s 25ms/step - loss: 249.7935 - val_loss: 202.5953\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 14s 25ms/step - loss: 217.5194 - val_loss: 299.5486\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 14s 25ms/step - loss: 184.9106 - val_loss: 161.4923\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 14s 25ms/step - loss: 180.3705 - val_loss: 118.3829\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 94.9231 - val_loss: 81.9326\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 68.2060 - val_loss: 83.6615\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 69.1412 - val_loss: 77.8580\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 15s 28ms/step - loss: 61.6431 - val_loss: 70.7641\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 59.5636 - val_loss: 117.7047\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 69.0589 - val_loss: 67.1189\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 59.0989 - val_loss: 68.3954\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 57.5506 - val_loss: 83.3859\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 281.9267 - val_loss: 2104.4109\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 16138420.0000 - val_loss: 903.1770\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 62675.1641 - val_loss: 526.0665\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 646.5074 - val_loss: 554.5016\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 640.2762 - val_loss: 522.3641\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 639.5883 - val_loss: 519.1286\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 637.1215 - val_loss: 521.0959\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 643.1787 - val_loss: 496.3823\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 629.2119 - val_loss: 475.9409\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 628.4250 - val_loss: 515.3339\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 632.0573 - val_loss: 540.1255\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 615.8679 - val_loss: 517.8492\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 618.7619 - val_loss: 492.5758\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 612.4830 - val_loss: 514.9985\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 609.6292 - val_loss: 533.1710\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 611.4969 - val_loss: 497.1972\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 605.9907 - val_loss: 491.9130\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 14s 26ms/step - loss: 610.7610 - val_loss: 474.6167\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 606.4099 - val_loss: 461.0982\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 15s 27ms/step - loss: 602.6472 - val_loss: 490.3281\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 20s 35ms/step - loss: 603.7759 - val_loss: 469.2826\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 15s 27ms/step - loss: 605.4609 - val_loss: 481.4398\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 16s 29ms/step - loss: 605.5042 - val_loss: 453.6268\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 15s 28ms/step - loss: 600.0900 - val_loss: 466.9851\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 16s 28ms/step - loss: 624.3661 - val_loss: 470.1927\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 16s 28ms/step - loss: 601.4359 - val_loss: 477.0942\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 16s 29ms/step - loss: 596.4681 - val_loss: 486.6483\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 15s 26ms/step - loss: 605.5397 - val_loss: 479.2662\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 15s 27ms/step - loss: 597.6083 - val_loss: 528.3000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', return_sequences= True,  input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('3LayerLSTM643216.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.7189686860114571\n",
      "RMSE:  22.98478131989393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (17826, 1, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "subsequences = 1\n",
    "timesteps = train_X.shape[1]//subsequences\n",
    "train_X = train_X.reshape((train_X.shape[0], subsequences, timesteps, 1))\n",
    "test_X = test_X.reshape((test_X.shape[0], subsequences, timesteps, 1))\n",
    "print('Train set shape', train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "558/558 [==============================] - 5s 6ms/step - loss: 487.2914 - val_loss: 199.7863\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 157.0451 - val_loss: 164.0298\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 123.7813 - val_loss: 169.7198\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 114.9194 - val_loss: 171.2453\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 110.6642 - val_loss: 178.3033\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 105.5520 - val_loss: 179.7160\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 108.0467 - val_loss: 176.8785\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 103.4055 - val_loss: 183.7424\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 101.6039 - val_loss: 242.0047\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 101.2677 - val_loss: 186.8869\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 98.1403 - val_loss: 423.1257\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 107.3196 - val_loss: 188.7824\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 97.4430 - val_loss: 201.1475\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 96.3994 - val_loss: 202.6764\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 95.9195 - val_loss: 194.4377\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 97.6913 - val_loss: 193.5958\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 95.9346 - val_loss: 196.6014\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 95.3918 - val_loss: 210.9673\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 99.5660 - val_loss: 203.5595\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 94.8427 - val_loss: 200.4847\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 97.2062 - val_loss: 201.4220\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 99.7644 - val_loss: 190.0758\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 94.6488 - val_loss: 203.8877\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 98.2682 - val_loss: 205.2281\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 95.5759 - val_loss: 200.9723\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 98.3195 - val_loss: 218.0736\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 94.3189 - val_loss: 194.8652\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 95.2711 - val_loss: 197.0995\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 94.3796 - val_loss: 217.2151\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 96.1165 - val_loss: 190.3891\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 92.9299 - val_loss: 202.5010\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 3s 6ms/step - loss: 95.2799 - val_loss: 198.7728\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 4s 7ms/step - loss: 94.6586 - val_loss: 206.7819\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 4s 7ms/step - loss: 96.8986 - val_loss: 205.1472\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 92.6055 - val_loss: 201.6906\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 93.9248 - val_loss: 212.3860\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 92.6166 - val_loss: 214.6336\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 92.9133 - val_loss: 202.2706\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 95.4352 - val_loss: 205.6260\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 93.5832 - val_loss: 207.8053\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 92.7722 - val_loss: 212.7626\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 94.6324 - val_loss: 245.1081\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 95.7977 - val_loss: 211.3569\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 92.7862 - val_loss: 228.7979\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 94.6727 - val_loss: 219.6050\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 94.2496 - val_loss: 270.6613\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 93.0405 - val_loss: 213.2757\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 91.1552 - val_loss: 202.2334\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 93.6364 - val_loss: 211.0530\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 93.3636 - val_loss: 211.1720\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, MaxPooling1D, Flatten, Conv1D, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Flatten()))\n",
    "model_cnn_lstm.add(LSTM(50, activation='relu'))\n",
    "model_cnn_lstm.add(Dense(1))\n",
    "model_cnn_lstm.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_cnn_lstm.compile(optimizer=optimizer, loss='mse')\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('CNNLSTM50.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model_cnn_lstm.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], subsequences, timesteps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features)) this is already done above\n",
    "pred_y = model_cnn_lstm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8876662352494111\n",
      "RMSE:  14.531758647404613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 cnn lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 45\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y165sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_X, train_y \u001b[39m=\u001b[39m split_sequence(train_data[\u001b[39m'\u001b[39m\u001b[39msfu\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m27\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y165sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# print(\"train split done\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y165sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_X, test_y \u001b[39m=\u001b[39m split_sequence(np\u001b[39m.\u001b[39marray(test_data[\u001b[39m'\u001b[39m\u001b[39msfu\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m27\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (17826, 1, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "subsequences = 1\n",
    "timesteps = train_X.shape[1]//subsequences\n",
    "train_X = train_X.reshape((train_X.shape[0], subsequences, timesteps, 1))\n",
    "test_X = test_X.reshape((test_X.shape[0], subsequences, timesteps, 1))\n",
    "print('Train set shape', train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 4s 5ms/step - loss: 913.4976 - val_loss: 347.9606\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 324.7936 - val_loss: 247.4067\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 250.7277 - val_loss: 240.4401\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 215.2297 - val_loss: 239.6161\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 206.4836 - val_loss: 222.4698\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 208.6369 - val_loss: 247.5169\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 199.2776 - val_loss: 367.9029\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 198.8256 - val_loss: 245.8838\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 182.8514 - val_loss: 250.3825\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 182.3668 - val_loss: 231.2024\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 182.2948 - val_loss: 274.3831\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 175.0298 - val_loss: 232.0128\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 173.3030 - val_loss: 222.5819\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 174.2974 - val_loss: 453.0663\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 169.0653 - val_loss: 229.1742\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 167.3180 - val_loss: 281.1208\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 164.1868 - val_loss: 215.1764\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 164.9800 - val_loss: 213.9874\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 162.1092 - val_loss: 228.1825\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 163.6849 - val_loss: 206.1698\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 155.1809 - val_loss: 233.6063\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 155.6495 - val_loss: 276.9662\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 155.3187 - val_loss: 231.3120\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 153.3786 - val_loss: 225.4981\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 153.9873 - val_loss: 227.8692\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 152.1450 - val_loss: 240.6509\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 151.9770 - val_loss: 226.6466\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 150.6990 - val_loss: 227.2713\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 147.7916 - val_loss: 255.4205\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 148.2844 - val_loss: 260.9478\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 146.5642 - val_loss: 217.3755\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 146.0421 - val_loss: 226.8302\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 147.2610 - val_loss: 246.7104\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 143.6776 - val_loss: 239.5787\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 144.4954 - val_loss: 229.3665\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 143.7803 - val_loss: 226.0023\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 143.7706 - val_loss: 234.1323\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 141.0954 - val_loss: 231.6901\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 3s 5ms/step - loss: 140.5890 - val_loss: 228.6832\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 142.8455 - val_loss: 239.8884\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 142.7257 - val_loss: 248.0761\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 141.0113 - val_loss: 259.5564\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 142.1487 - val_loss: 230.5131\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 141.6258 - val_loss: 264.3201\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 140.5940 - val_loss: 283.5367\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 143.6043 - val_loss: 263.1942\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 140.6775 - val_loss: 259.2906\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 140.0109 - val_loss: 255.2757\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 140.1130 - val_loss: 253.2062\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 137.7129 - val_loss: 253.2006\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, MaxPooling1D, Flatten, Conv1D, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=64, kernel_size=4,  activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=32, kernel_size=4, activation='relu')))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Flatten()))\n",
    "model_cnn_lstm.add(LSTM(50, activation='relu'))\n",
    "model_cnn_lstm.add(Dense(1))\n",
    "model_cnn_lstm.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_cnn_lstm.compile(optimizer=optimizer, loss='mse')\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('CNNLSTM50.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model_cnn_lstm.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features)) this is already done above\n",
    "pred_y = model_cnn_lstm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8653090218222668\n",
      "RMSE:  15.912274885888893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2CNN2LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 51\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y204sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_X, train_y \u001b[39m=\u001b[39m split_sequence(train_data[\u001b[39m'\u001b[39m\u001b[39msfu\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m27\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y204sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# print(\"train split done\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y204sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_X, test_y \u001b[39m=\u001b[39m split_sequence(np\u001b[39m.\u001b[39marray(test_data[\u001b[39m'\u001b[39m\u001b[39msfu\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m27\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "train_X, train_y = split_sequence(train_data['sfu'], 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 5s 4ms/step - loss: 1006.8510 - val_loss: 188.0398\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 140.0676 - val_loss: 168.9059\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 102.4285 - val_loss: 138.0965\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 85.6422 - val_loss: 142.0436\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 80.8391 - val_loss: 145.2811\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 68.6636 - val_loss: 130.9130\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 66.2465 - val_loss: 136.9543\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 62.9630 - val_loss: 134.9906\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 59.6860 - val_loss: 135.2012\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 56.8915 - val_loss: 118.3665\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 52.8200 - val_loss: 111.6011\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 49.8132 - val_loss: 114.0813\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 49.3424 - val_loss: 109.5876\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 45.9122 - val_loss: 113.7907\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 47.4818 - val_loss: 106.6955\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 42.2266 - val_loss: 109.1469\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 44.7503 - val_loss: 115.5696\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 42.5490 - val_loss: 118.7640\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 42.1187 - val_loss: 208.2260\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 48.4989 - val_loss: 137.1595\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 45.3273 - val_loss: 126.0190\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 41.4790 - val_loss: 140.9329\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 40.9579 - val_loss: 137.9347\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 43.4667 - val_loss: 154.7598\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 40.0537 - val_loss: 136.9733\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 39.8362 - val_loss: 132.7344\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 37.8125 - val_loss: 136.3946\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.2165 - val_loss: 143.1379\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.8838 - val_loss: 163.4757\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 40.3289 - val_loss: 140.6747\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.0684 - val_loss: 143.8315\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 37.2901 - val_loss: 145.9030\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.5087 - val_loss: 142.4808\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.0604 - val_loss: 158.7445\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.3585 - val_loss: 144.1850\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 36.9604 - val_loss: 163.7162\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.8401 - val_loss: 143.4258\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.2299 - val_loss: 146.3379\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 33.2567 - val_loss: 145.8943\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.9071 - val_loss: 144.5885\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 34.7499 - val_loss: 147.3275\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 34.6276 - val_loss: 158.6191\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.6381 - val_loss: 147.1632\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 32.2960 - val_loss: 148.2688\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.5900 - val_loss: 146.1707\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 34.3588 - val_loss: 152.4002\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 35.1873 - val_loss: 151.8034\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 33.3351 - val_loss: 146.0912\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 33.9380 - val_loss: 141.1768\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 2s 4ms/step - loss: 32.9682 - val_loss: 141.5648\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, MaxPooling1D, Flatten, Conv1D, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=16, kernel_size=14,  activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=32, kernel_size=4, activation='relu')))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Flatten()))\n",
    "model_cnn_lstm.add(LSTM(64, activation='relu', return_sequences= True))\n",
    "model_cnn_lstm.add(LSTM(32, activation='relu'))\n",
    "model_cnn_lstm.add(Dense(1))\n",
    "model_cnn_lstm.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_cnn_lstm.compile(optimizer=optimizer, loss='mse')\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('CNNLSTM6432.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model_cnn_lstm.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features)) this is already done above\n",
    "pred_y = model_cnn_lstm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9246940528516168\n",
      "RMSE:  11.898101151860521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(np.array(train_data['sfu']), 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843/843 [==============================] - 10s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "843/843 [==============================] - 10s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "841/843 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 54\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y110sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mmodel_weightsSGD.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y110sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Fit model with checkpointing\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y110sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (test_X, test_y), callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1939\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1937\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_test_counter\u001b[39m.\u001b[39massign(\u001b[39m0\u001b[39m)\n\u001b[0;32m   1938\u001b[0m callbacks\u001b[39m.\u001b[39mon_test_begin()\n\u001b[1;32m-> 1939\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n\u001b[0;32m   1941\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\data_adapter.py:1307\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1307\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[0;32m   1308\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1309\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    698\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource \u001b[39m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[39m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3409\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3410\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimzer = Adam(lr = 0.001)\n",
    "# optimizer = SGD(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('model_weightsSGD.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(X, y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(np.array(train_data['sfu']), 27)\n",
    "# print(\"train split done\")\n",
    "test_X, test_y = split_sequence(np.array(test_data['sfu']), 27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 layer with dropout and leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "558/558 [==============================] - 56s 90ms/step - loss: 14311.6025 - val_loss: 6005.9253\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 52s 93ms/step - loss: 8604.9766 - val_loss: 3163.3945\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 52s 94ms/step - loss: 5526.4844 - val_loss: 2057.0815\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 51s 91ms/step - loss: 4035.6338 - val_loss: 1889.8063\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 50s 89ms/step - loss: 3468.4131 - val_loss: 2069.3254\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 48s 87ms/step - loss: 3295.4119 - val_loss: 2266.9373\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 3253.5493 - val_loss: 2354.8044\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 45s 82ms/step - loss: 2863.6934 - val_loss: 569.0808\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 47s 85ms/step - loss: 1284.1479 - val_loss: 286.5464\n",
      "Epoch 10/50\n",
      "558/558 [==============================] - 46s 82ms/step - loss: 770.7077 - val_loss: 193.1290\n",
      "Epoch 11/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 536.0413 - val_loss: 126.1788\n",
      "Epoch 12/50\n",
      "558/558 [==============================] - 45s 80ms/step - loss: 399.1795 - val_loss: 103.2092\n",
      "Epoch 13/50\n",
      "558/558 [==============================] - 45s 80ms/step - loss: 322.6340 - val_loss: 82.1385\n",
      "Epoch 14/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 287.2113 - val_loss: 106.7774\n",
      "Epoch 15/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 246.7974 - val_loss: 91.2130\n",
      "Epoch 16/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 232.1304 - val_loss: 59.9391\n",
      "Epoch 17/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 219.1085 - val_loss: 87.5973\n",
      "Epoch 18/50\n",
      "558/558 [==============================] - 45s 81ms/step - loss: 203.4418 - val_loss: 60.1568\n",
      "Epoch 19/50\n",
      "558/558 [==============================] - 48s 85ms/step - loss: 207.2223 - val_loss: 66.1604\n",
      "Epoch 20/50\n",
      "558/558 [==============================] - 47s 84ms/step - loss: 195.3884 - val_loss: 58.3294\n",
      "Epoch 21/50\n",
      "558/558 [==============================] - 46s 82ms/step - loss: 191.7676 - val_loss: 56.5386\n",
      "Epoch 22/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 188.0895 - val_loss: 56.6847\n",
      "Epoch 23/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 186.0946 - val_loss: 75.9824\n",
      "Epoch 24/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 180.1271 - val_loss: 56.4360\n",
      "Epoch 25/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 176.7949 - val_loss: 58.0350\n",
      "Epoch 26/50\n",
      "558/558 [==============================] - 49s 87ms/step - loss: 173.9726 - val_loss: 65.0396\n",
      "Epoch 27/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 178.7332 - val_loss: 58.0116\n",
      "Epoch 28/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 172.5682 - val_loss: 57.1898\n",
      "Epoch 29/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 174.8174 - val_loss: 89.6535\n",
      "Epoch 30/50\n",
      "558/558 [==============================] - 47s 85ms/step - loss: 179.7082 - val_loss: 56.4514\n",
      "Epoch 31/50\n",
      "558/558 [==============================] - 47s 85ms/step - loss: 169.8274 - val_loss: 55.8018\n",
      "Epoch 32/50\n",
      "558/558 [==============================] - 47s 84ms/step - loss: 168.9565 - val_loss: 77.6112\n",
      "Epoch 33/50\n",
      "558/558 [==============================] - 48s 85ms/step - loss: 173.7590 - val_loss: 70.6197\n",
      "Epoch 34/50\n",
      "558/558 [==============================] - 47s 85ms/step - loss: 171.9490 - val_loss: 61.5530\n",
      "Epoch 35/50\n",
      "558/558 [==============================] - 47s 85ms/step - loss: 170.3648 - val_loss: 64.7055\n",
      "Epoch 36/50\n",
      "558/558 [==============================] - 48s 85ms/step - loss: 165.3904 - val_loss: 58.4470\n",
      "Epoch 37/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 168.8089 - val_loss: 61.4567\n",
      "Epoch 38/50\n",
      "558/558 [==============================] - 48s 85ms/step - loss: 168.8138 - val_loss: 61.6380\n",
      "Epoch 39/50\n",
      "558/558 [==============================] - 48s 85ms/step - loss: 166.5239 - val_loss: 69.8393\n",
      "Epoch 40/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 167.3646 - val_loss: 57.5500\n",
      "Epoch 41/50\n",
      "558/558 [==============================] - 48s 86ms/step - loss: 163.1069 - val_loss: 57.0423\n",
      "Epoch 42/50\n",
      "558/558 [==============================] - 49s 87ms/step - loss: 164.8074 - val_loss: 63.1796\n",
      "Epoch 43/50\n",
      "558/558 [==============================] - 48s 87ms/step - loss: 162.7738 - val_loss: 63.1688\n",
      "Epoch 44/50\n",
      "558/558 [==============================] - 48s 87ms/step - loss: 166.9396 - val_loss: 57.7539\n",
      "Epoch 45/50\n",
      "558/558 [==============================] - 48s 87ms/step - loss: 164.6303 - val_loss: 62.4684\n",
      "Epoch 46/50\n",
      "558/558 [==============================] - 49s 87ms/step - loss: 162.1066 - val_loss: 60.3715\n",
      "Epoch 47/50\n",
      "558/558 [==============================] - 50s 90ms/step - loss: 156.1075 - val_loss: 58.7754\n",
      "Epoch 48/50\n",
      "558/558 [==============================] - 50s 90ms/step - loss: 163.8911 - val_loss: 62.9315\n",
      "Epoch 49/50\n",
      "558/558 [==============================] - 49s 87ms/step - loss: 161.2949 - val_loss: 57.9195\n",
      "Epoch 50/50\n",
      "558/558 [==============================] - 49s 88ms/step - loss: 162.5389 - val_loss: 67.2204\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, LeakyReLU, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_features = 1\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences= True,  input_shape=(n_steps, n_features)))\n",
    "model.add(LeakyReLU(alpha = 0.5))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LeakyReLU(alpha = 0.5))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('3LayerLSTM643216.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit model with checkpointing\n",
    "history = model.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 27, 128)           66560     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 27, 128)           131584    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 27, 128)           0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 27, 128)           0         \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 247,617\n",
      "Trainable params: 247,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_Stopping =EarlyStopping(monitor = 'val_loss'\n",
    "                              patience = 5, \n",
    "                              mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 10s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.964241858872422\n",
      "RMSE:  8.19880365836983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Assuming you have your true values in 'y_true' and predicted values in 'y_pred'\n",
    "r2 = r2_score(test_y, pred_y)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (17826, 1, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "subsequences = 1\n",
    "timesteps = train_X.shape[1]//subsequences\n",
    "train_X = train_X.reshape((train_X.shape[0], subsequences, timesteps, 1))\n",
    "test_X = test_X.reshape((test_X.shape[0], subsequences, timesteps, 1))\n",
    "print('Train set shape', train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "558/558 [==============================] - 10s 10ms/step - loss: 5388.0488 - val_loss: 2426.9719\n",
      "Epoch 2/50\n",
      "558/558 [==============================] - 5s 8ms/step - loss: 3415.8975 - val_loss: 2189.0471\n",
      "Epoch 3/50\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 3419.0452 - val_loss: 2394.7275\n",
      "Epoch 4/50\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 3410.2253 - val_loss: 2539.8289\n",
      "Epoch 5/50\n",
      "558/558 [==============================] - 5s 8ms/step - loss: 3407.8948 - val_loss: 2287.3403\n",
      "Epoch 6/50\n",
      "558/558 [==============================] - 5s 8ms/step - loss: 3411.4451 - val_loss: 2452.6375\n",
      "Epoch 7/50\n",
      "558/558 [==============================] - 5s 8ms/step - loss: 3408.1262 - val_loss: 2557.9590\n",
      "Epoch 8/50\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 3410.2280 - val_loss: 2449.3931\n",
      "Epoch 9/50\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 3410.9556 - val_loss: 2292.1445\n",
      "Epoch 10/50\n",
      "258/558 [============>.................] - ETA: 2s - loss: 3415.4353"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Swaroop\\isro project\\experimenting.ipynb Cell 70\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y134sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Define checkpoint callback\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y134sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mCNNLSTM6432.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Swaroop/isro%20project/experimenting.ipynb#Y134sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m history \u001b[39m=\u001b[39m model_cnn_lstm\u001b[39m.\u001b[39;49mfit(train_X, train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (test_X, test_y), callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Swaroop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, MaxPooling1D, Flatten, Conv1D, TimeDistributed, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=64, kernel_size=14, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "# model_cnn_lstm.add(LeakyReLU(alpha =0.5))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Conv1D(filters=32, kernel_size=4, activation='relu')))\n",
    "# model_cnn_lstm.add(LeakyReLU(alpha =0.5))\n",
    "model_cnn_lstm.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model_cnn_lstm.add(TimeDistributed(Flatten()))\n",
    "model_cnn_lstm.add(LSTM(128, return_sequences= True))\n",
    "model_cnn_lstm.add(LeakyReLU(alpha =0.5))\n",
    "model_cnn_lstm.add(LSTM(128, return_sequences= True))\n",
    "model_cnn_lstm.add(LeakyReLU(alpha =0.5))\n",
    "model_cnn_lstm.add(Dropout(0.3))\n",
    "model_cnn_lstm.add(LSTM(64, activation='relu', return_sequences= True))\n",
    "model_cnn_lstm.add(Dropout(0.3))\n",
    "model_cnn_lstm.add(Dense(1))\n",
    "model_cnn_lstm.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_cnn_lstm.compile(optimizer=optimizer, loss='mse')\n",
    "# Define checkpoint callback\n",
    "checkpoint = ModelCheckpoint('CNNLSTM6432.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = model_cnn_lstm.fit(train_X, train_y, epochs=50, verbose=1, validation_data = (test_X, test_y), callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
